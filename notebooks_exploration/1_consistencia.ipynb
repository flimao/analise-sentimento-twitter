{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Análise de consistência dos dados\n",
    "\n",
    "Nessa fase, analisaremos se os dados estão fazendo sentido, se os campos estão completos e se há dados duplicados ou faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos dados\n",
    "\n",
    "Primeiramente, importamos os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# não tocaremos no conjunto de submissão\n",
    "\n",
    "tweets_raw = pd.read_csv(\n",
    "    r'../data/Train3Classes.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1049721159292346368</td>\n",
       "      <td>Rio elege maior bancada policial de sua histór...</td>\n",
       "      <td>Tue Oct 09 18:00:01 +0000 2018</td>\n",
       "      <td>2</td>\n",
       "      <td>folha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046251157025423360</td>\n",
       "      <td>fiquei tão triste quando eu vi o preço da câme...</td>\n",
       "      <td>Sun Sep 30 04:11:28 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041744620206653440</td>\n",
       "      <td>Para Theresa May, seu plano para o Brexit é a ...</td>\n",
       "      <td>Mon Sep 17 17:44:06 +0000 2018</td>\n",
       "      <td>2</td>\n",
       "      <td>exame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1046937084727107589</td>\n",
       "      <td>caralho eu quero proteger a danielly em um pot...</td>\n",
       "      <td>Tue Oct 02 01:37:06 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1047326854229778432</td>\n",
       "      <td>@SiCaetano_ viva o caos :)</td>\n",
       "      <td>Wed Oct 03 03:25:55 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                         tweet_text  \\\n",
       "0  1049721159292346368  Rio elege maior bancada policial de sua histór...   \n",
       "1  1046251157025423360  fiquei tão triste quando eu vi o preço da câme...   \n",
       "2  1041744620206653440  Para Theresa May, seu plano para o Brexit é a ...   \n",
       "3  1046937084727107589  caralho eu quero proteger a danielly em um pot...   \n",
       "4  1047326854229778432                         @SiCaetano_ viva o caos :)   \n",
       "\n",
       "                       tweet_date  sentiment query_used  \n",
       "0  Tue Oct 09 18:00:01 +0000 2018          2      folha  \n",
       "1  Sun Sep 30 04:11:28 +0000 2018          0         :(  \n",
       "2  Mon Sep 17 17:44:06 +0000 2018          2      exame  \n",
       "3  Tue Oct 02 01:37:06 +0000 2018          0         :(  \n",
       "4  Wed Oct 03 03:25:55 +0000 2018          1         :)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95000 entries, 0 to 94999\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          95000 non-null  int64 \n",
      " 1   tweet_text  95000 non-null  object\n",
      " 2   tweet_date  95000 non-null  object\n",
      " 3   sentiment   95000 non-null  int64 \n",
      " 4   query_used  95000 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformações básicas\n",
    "\n",
    "Vamos fazer algumas transformações básicas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mudar_tipos(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df['id'] = df['id'].astype('string')\n",
    "    df['tweet_date'] = pd.to_datetime(df['tweet_date'])\n",
    "    df['sentiment'] = df['sentiment'].astype('category')\n",
    "\n",
    "    return df\n",
    "\n",
    "def setar_index(df):\n",
    "    # somente será aplicado após remção de duplicatas\n",
    "    df = df.copy()\n",
    "    df = df.set_index('id')\n",
    "    return df\n",
    "\n",
    "tweets = (tweets_raw\n",
    "    .pipe(mudar_tipos)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95000 entries, 0 to 94999\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype              \n",
      "---  ------      --------------  -----              \n",
      " 0   id          95000 non-null  string             \n",
      " 1   tweet_text  95000 non-null  object             \n",
      " 2   tweet_date  95000 non-null  datetime64[ns, UTC]\n",
      " 3   sentiment   95000 non-null  category           \n",
      " 4   query_used  95000 non-null  object             \n",
      "dtypes: category(1), datetime64[ns, UTC](1), object(2), string(1)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1049721159292346368</td>\n",
       "      <td>Rio elege maior bancada policial de sua histór...</td>\n",
       "      <td>2018-10-09 18:00:01+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>folha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046251157025423360</td>\n",
       "      <td>fiquei tão triste quando eu vi o preço da câme...</td>\n",
       "      <td>2018-09-30 04:11:28+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041744620206653440</td>\n",
       "      <td>Para Theresa May, seu plano para o Brexit é a ...</td>\n",
       "      <td>2018-09-17 17:44:06+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>exame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1046937084727107589</td>\n",
       "      <td>caralho eu quero proteger a danielly em um pot...</td>\n",
       "      <td>2018-10-02 01:37:06+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1047326854229778432</td>\n",
       "      <td>@SiCaetano_ viva o caos :)</td>\n",
       "      <td>2018-10-03 03:25:55+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                         tweet_text  \\\n",
       "0  1049721159292346368  Rio elege maior bancada policial de sua histór...   \n",
       "1  1046251157025423360  fiquei tão triste quando eu vi o preço da câme...   \n",
       "2  1041744620206653440  Para Theresa May, seu plano para o Brexit é a ...   \n",
       "3  1046937084727107589  caralho eu quero proteger a danielly em um pot...   \n",
       "4  1047326854229778432                         @SiCaetano_ viva o caos :)   \n",
       "\n",
       "                 tweet_date sentiment query_used  \n",
       "0 2018-10-09 18:00:01+00:00         2      folha  \n",
       "1 2018-09-30 04:11:28+00:00         0         :(  \n",
       "2 2018-09-17 17:44:06+00:00         2      exame  \n",
       "3 2018-10-02 01:37:06+00:00         0         :(  \n",
       "4 2018-10-03 03:25:55+00:00         1         :)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de consistência\n",
    "\n",
    "Vamos analisar se a base está completa, sem dados faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95000 entries, 0 to 94999\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype              \n",
      "---  ------      --------------  -----              \n",
      " 0   id          95000 non-null  string             \n",
      " 1   tweet_text  95000 non-null  object             \n",
      " 2   tweet_date  95000 non-null  datetime64[ns, UTC]\n",
      " 3   sentiment   95000 non-null  category           \n",
      " 4   query_used  95000 non-null  object             \n",
      "dtypes: category(1), datetime64[ns, UTC](1), object(2), string(1)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não há dados faltantes.\n",
    "\n",
    "Vejamos se há dados em que algum campo não está preenchido (ao invés de `np.nan`, pode estar como string nula, `''`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, tweet_text, tweet_date, sentiment, query_used]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\n",
    "    (tweets.tweet_text == '') |\n",
    "    (tweets.query_used == '')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2], dtype='int64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sentiment.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95000</td>\n",
       "      <td>95000</td>\n",
       "      <td>95000</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>94987</td>\n",
       "      <td>94184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1040377082189172738</td>\n",
       "      <td>Bom dia :)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31696.0</td>\n",
       "      <td>31696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-28 18:18:50.530284032+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-08-09 01:59:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-27 17:50:36.500000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-01 18:20:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-08 01:16:52+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-19 18:40:47+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  tweet_text                           tweet_date  \\\n",
       "count                 95000       95000                                95000   \n",
       "unique                94987       94184                                  NaN   \n",
       "top     1040377082189172738  Bom dia :)                                  NaN   \n",
       "freq                      2          30                                  NaN   \n",
       "mean                    NaN         NaN  2018-09-28 18:18:50.530284032+00:00   \n",
       "min                     NaN         NaN            2018-08-09 01:59:00+00:00   \n",
       "25%                     NaN         NaN     2018-09-27 17:50:36.500000+00:00   \n",
       "50%                     NaN         NaN            2018-10-01 18:20:00+00:00   \n",
       "75%                     NaN         NaN            2018-10-08 01:16:52+00:00   \n",
       "max                     NaN         NaN            2018-10-19 18:40:47+00:00   \n",
       "\n",
       "        sentiment query_used  \n",
       "count     95000.0      95000  \n",
       "unique        3.0         14  \n",
       "top           0.0         :(  \n",
       "freq      31696.0      31696  \n",
       "mean          NaN        NaN  \n",
       "min           NaN        NaN  \n",
       "25%           NaN        NaN  \n",
       "50%           NaN        NaN  \n",
       "75%           NaN        NaN  \n",
       "max           NaN        NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.describe(datetime_is_numeric = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vamos ver se há dados duplicados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4777                                Veja o que é #FATO ou #FAKE na entrevista de Fernando Haddad para o Jornal da Globo. https://t.co/v0yFR5LRC1 https://t.co/fnbcEnrz9j\n",
       "17419                                                  Veja o que é #FATO ou #FAKE na sabatina de Marina Silva no GLOBO. https://t.co/KOZduYQanr https://t.co/DEidfc1pz5\n",
       "18026                                                    Veja o que é #FATO ou #FAKE na sabatina de Ciro Gomes no GLOBO. https://t.co/jmPEAZcTbX https://t.co/79w5eSp4p3\n",
       "20226                                                 Veja o que é #FATO ou #FAKE na entrevista de Eymael ao G1 e à CBN. https://t.co/SkbV38GESy https://t.co/Zc9GQzYCjp\n",
       "21547                                                                    Veja o que é #FATO ou #FAKE na entrevista de Anthony Garotinho ao RJTV. https://t.co/9EpMm0jVwv\n",
       "28564                               Veja o que é #FATO ou #FAKE na entrevista de Fernando Haddad para o Jornal Nacional. https://t.co/PAUdomrbUu https://t.co/HIOnprgHbl\n",
       "30744                                               Veja o que é #FATO ou #FAKE na sabatina de Geraldo Alckmin no GLOBO. https://t.co/qfdRI5Iq4m https://t.co/Jc676CZisr\n",
       "32410                                               Veja o que é #FATO ou #FAKE na sabatina de Geraldo Alckmin no GLOBO. https://t.co/qfdRI5Iq4m https://t.co/Jc676CZisr\n",
       "34464    era para ser somente algo normal, sem perceber nem notei e me entregue :) #internauta #trabalho #amor #ficaadica #jornalismo #imprensa — se sentindo apaixonado\n",
       "35012                                                 Veja o que é #FATO ou #FAKE na entrevista de Eymael ao G1 e à CBN. https://t.co/SkbV38GESy https://t.co/Zc9GQzYCjp\n",
       "35849                                          Veja o que é #FATO ou #FAKE na entrevista de Hamilton Mourão à GloboNews. https://t.co/VuwwDojIKY https://t.co/9QV2JLCFhT\n",
       "38913                                             O que é #FATO ou #FAKE na entrevista de Geraldo Alckmin ao G1 e à CBN. https://t.co/fUHx5Adr84 https://t.co/638pPGleve\n",
       "39007                               Veja o que é #FATO ou #FAKE na entrevista de Fernando Haddad para o Jornal da Globo. https://t.co/v0yFR5LRC1 https://t.co/fnbcEnrz9j\n",
       "39184                                             O que é #FATO ou #FAKE na entrevista de Geraldo Alckmin ao G1 e à CBN. https://t.co/fUHx5Adr84 https://t.co/638pPGleve\n",
       "39324                                          Veja o que é #FATO ou #FAKE na entrevista de Fernando Haddad à GloboNews: https://t.co/mqlxZTAm2M https://t.co/XeFvIqcz8X\n",
       "42936                                                  Veja o que é #FATO ou #FAKE na sabatina de Marina Silva no GLOBO. https://t.co/KOZduYQanr https://t.co/DEidfc1pz5\n",
       "48967    era para ser somente algo normal, sem perceber nem notei e me entregue :) #internauta #trabalho #amor #ficaadica #jornalismo #imprensa — se sentindo apaixonado\n",
       "56550                                                                    Veja o que é #FATO ou #FAKE na entrevista de Anthony Garotinho ao RJTV. https://t.co/9EpMm0jVwv\n",
       "62236                                           Veja o que é #FATO ou #FAKE na entrevista de Hamilton Mourão à GloboNews https://t.co/63tEfprsH8 https://t.co/94IoL8HmIO\n",
       "65328                                   Veja o que é #FATO ou #FAKE na entrevista de Marina Silva para o Jornal da Globo https://t.co/MGusFe6vXr https://t.co/vQzX8btrbS\n",
       "66221                               Veja o que é #FATO ou #FAKE na entrevista de Fernando Haddad para o Jornal Nacional. https://t.co/PAUdomrbUu https://t.co/HIOnprgHbl\n",
       "68291                                                    Veja o que é #FATO ou #FAKE na sabatina de Ciro Gomes no GLOBO. https://t.co/jmPEAZcTbX https://t.co/79w5eSp4p3\n",
       "69100                                          Veja o que é #FATO ou #FAKE na entrevista de Hamilton Mourão à GloboNews. https://t.co/VuwwDojIKY https://t.co/9QV2JLCFhT\n",
       "83565                                          Veja o que é #FATO ou #FAKE na entrevista de Fernando Haddad à GloboNews: https://t.co/mqlxZTAm2M https://t.co/XeFvIqcz8X\n",
       "87130                                   Veja o que é #FATO ou #FAKE na entrevista de Marina Silva para o Jornal da Globo https://t.co/MGusFe6vXr https://t.co/vQzX8btrbS\n",
       "93665                                           Veja o que é #FATO ou #FAKE na entrevista de Hamilton Mourão à GloboNews https://t.co/63tEfprsH8 https://t.co/94IoL8HmIO\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "duplicados = tweets[tweets.duplicated(subset = 'id', keep = False)]\n",
    "\n",
    "with pd.option_context('display.max_colwidth', 500):\n",
    "    display(duplicados.tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicados.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Há 26 *tweets* duplicados. Vamos manter somente uma cópia de cada duplicata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1049721159292346368</td>\n",
       "      <td>Rio elege maior bancada policial de sua histór...</td>\n",
       "      <td>2018-10-09 18:00:01+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>folha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046251157025423360</td>\n",
       "      <td>fiquei tão triste quando eu vi o preço da câme...</td>\n",
       "      <td>2018-09-30 04:11:28+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041744620206653440</td>\n",
       "      <td>Para Theresa May, seu plano para o Brexit é a ...</td>\n",
       "      <td>2018-09-17 17:44:06+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>exame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1046937084727107589</td>\n",
       "      <td>caralho eu quero proteger a danielly em um pot...</td>\n",
       "      <td>2018-10-02 01:37:06+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1047326854229778432</td>\n",
       "      <td>@SiCaetano_ viva o caos :)</td>\n",
       "      <td>2018-10-03 03:25:55+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94995</th>\n",
       "      <td>1041831666883321856</td>\n",
       "      <td>Cuba e defensor de direitos humanos se unem co...</td>\n",
       "      <td>2018-09-17 23:30:00+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>jornaloglobo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94996</th>\n",
       "      <td>1032352892194369536</td>\n",
       "      <td>#Oportunidade ➡️ Venha fazer parte da nossa eq...</td>\n",
       "      <td>2018-08-22 19:44:44+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>#oportunidade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94997</th>\n",
       "      <td>1046785538542440448</td>\n",
       "      <td>@96syoo EU SEI 😭😭 é por isso que significa mui...</td>\n",
       "      <td>2018-10-01 15:34:55+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94998</th>\n",
       "      <td>1045457469110177792</td>\n",
       "      <td>@louistsexhes N te conheço mas posta :D</td>\n",
       "      <td>2018-09-27 23:37:38+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94999</th>\n",
       "      <td>1046239135286136832</td>\n",
       "      <td>meu deus :( https://t.co/BlXazxZeKq</td>\n",
       "      <td>2018-09-30 03:23:42+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94987 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                         tweet_text  \\\n",
       "0      1049721159292346368  Rio elege maior bancada policial de sua histór...   \n",
       "1      1046251157025423360  fiquei tão triste quando eu vi o preço da câme...   \n",
       "2      1041744620206653440  Para Theresa May, seu plano para o Brexit é a ...   \n",
       "3      1046937084727107589  caralho eu quero proteger a danielly em um pot...   \n",
       "4      1047326854229778432                         @SiCaetano_ viva o caos :)   \n",
       "...                    ...                                                ...   \n",
       "94995  1041831666883321856  Cuba e defensor de direitos humanos se unem co...   \n",
       "94996  1032352892194369536  #Oportunidade ➡️ Venha fazer parte da nossa eq...   \n",
       "94997  1046785538542440448  @96syoo EU SEI 😭😭 é por isso que significa mui...   \n",
       "94998  1045457469110177792            @louistsexhes N te conheço mas posta :D   \n",
       "94999  1046239135286136832                meu deus :( https://t.co/BlXazxZeKq   \n",
       "\n",
       "                     tweet_date sentiment     query_used  \n",
       "0     2018-10-09 18:00:01+00:00         2          folha  \n",
       "1     2018-09-30 04:11:28+00:00         0             :(  \n",
       "2     2018-09-17 17:44:06+00:00         2          exame  \n",
       "3     2018-10-02 01:37:06+00:00         0             :(  \n",
       "4     2018-10-03 03:25:55+00:00         1             :)  \n",
       "...                         ...       ...            ...  \n",
       "94995 2018-09-17 23:30:00+00:00         2   jornaloglobo  \n",
       "94996 2018-08-22 19:44:44+00:00         2  #oportunidade  \n",
       "94997 2018-10-01 15:34:55+00:00         0             :(  \n",
       "94998 2018-09-27 23:37:38+00:00         1             :)  \n",
       "94999 2018-09-30 03:23:42+00:00         0             :(  \n",
       "\n",
       "[94987 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.drop_duplicates(subset = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_duplicatas(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df.drop_duplicates(subset = 'id')\n",
    "\n",
    "    return df\n",
    "\n",
    "tweets = (tweets_raw\n",
    "    .pipe(mudar_tipos)\n",
    "    .pipe(remover_duplicatas)\n",
    "    .pipe(setar_index)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 94987 entries, 1049721159292346368 to 1046239135286136832\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype              \n",
      "---  ------      --------------  -----              \n",
      " 0   tweet_text  94987 non-null  object             \n",
      " 1   tweet_date  94987 non-null  datetime64[ns, UTC]\n",
      " 2   sentiment   94987 non-null  category           \n",
      " 3   query_used  94987 non-null  object             \n",
      "dtypes: category(1), datetime64[ns, UTC](1), object(2)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49c2d9072e237c44d0dfdf93edb0b2db9ca84a00f7fad675561ffcc6e7527ded"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('dsd': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
