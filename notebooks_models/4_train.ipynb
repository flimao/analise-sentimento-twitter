{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Treinamento de modelos\n",
    "\n",
    "Nessa fase, treinaremos os modelos classificadores candidatos. \n",
    "\n",
    "Nessa etapa o problema se torna semelhante aos modelos de ML tradicionais: testaremos diversos classificadores como *RandomForest*, *AdaBoost*, entre outros, e otimizaremos tamb√©m os hiperpar√¢metros do modelo com t√©cnicas como a *GridSearch* e a *RandomizedSearch*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caminho para instala√ß√£o do pacote mltoolkit, com metricas e gr√°ficos personalizados\n",
    "# !pip install git+ssh://git@github.com/flimao/mltoolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import rcParams, rcParamsDefault, pyplot as plt\n",
    "import seaborn as sns\n",
    "from mltoolkit import metrics, plots, NLP\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "rcParams.update(rcParamsDefault)\n",
    "rcParams['figure.dpi'] = 120\n",
    "rcParams['figure.figsize'] = (10, 8)\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download pt_core_news_lg\n",
    "# !python -m spacy download pt_core_news_md\n",
    "# !python -m spacy download pt_core_news_sm\n",
    "nlp = spacy.load(\"pt_core_news_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importa√ß√£o dos dados\n",
    "\n",
    "Primeiramente, importamos os dados e aplicamos as transforma√ß√µes utilizadas na fase anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n√£o tocaremos no conjunto de submiss√£o\n",
    "\n",
    "tweets_raw = pd.read_csv(\n",
    "    r'../data/Train3Classes.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trocar tipos para acelerar o processamento (menos espa√ßo em mem√≥ria)\n",
    "# e ativar poss√≠veis otimiza√ß√µes internas ao pandas para certos tipos\n",
    "def mudar_tipos(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df['id'] = df['id'].astype('string')\n",
    "    df['tweet_date'] = pd.to_datetime(df['tweet_date'])\n",
    "    df['sentiment'] = df['sentiment'].astype('category')\n",
    "\n",
    "    return df\n",
    "\n",
    "def remover_duplicatas(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df.drop_duplicates(subset = 'id')\n",
    "\n",
    "    return df\n",
    "\n",
    "# o √≠ndice √© o id, visto que n√£o h√° repetidos\n",
    "# vantagem: o √≠ndice √© removido automaticamente quando separamos em base de treino e teste.\n",
    "def setar_index(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df.set_index('id')\n",
    "\n",
    "    return df\n",
    "\n",
    "tweets_full = (tweets_raw\n",
    "    .pipe(mudar_tipos)\n",
    "    .pipe(remover_duplicatas)\n",
    "    .pipe(setar_index)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√©-processamento de texto\n",
    "\n",
    "Vamos ent√£o implementar o pr√©-processamento do texto da fase anterior (An√°lise Explorat√≥ria de Texto).\n",
    "\n",
    "Primeiramente vamos importar as *stopwords*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'../data/stopwords_alopes.txt', encoding = 'utf8') as stopword_list:\n",
    "    lst = stopword_list.read().splitlines()\n",
    "\n",
    "stopwords_alopes = set([ stopword.strip() for stopword in lst ])\n",
    "\n",
    "# em uma an√°lise de sentimento, n√£o queremos remover palavras com conota√ß√£o negativa\n",
    "remover_stopwords = {\n",
    "    'n√£o', \n",
    "}\n",
    "\n",
    "stopwords_alopes -= remover_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_full = lambda s: NLP.preprocessing(s, preproc_funs_args = [\n",
    "    NLP.remove_links,\n",
    "    NLP.remove_hashtags,\n",
    "    NLP.remove_mentions,\n",
    "    NLP.remove_numbers,\n",
    "    NLP.remove_special_caract,\n",
    "    NLP.lowercase,\n",
    "    #remove_punkt,\n",
    "    #(remove_stopwords, dict(stopword_list = stopword_list_alopes)),\n",
    "    (NLP.tokenize_remove_stopwords_get_radicals_spacy, dict(\n",
    "        nlp = nlp,\n",
    "        stopword_list = stopwords_alopes,\n",
    "    )),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ent√£o aplicar esse pr√©-processamento a uma amostra da base de *tweets* (para podermos iterar rapidamente caso necess√°rio). \n",
    "\n",
    "Em um momento posterior, treinaremos a base completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [00:24<00:00, 204.51it/s]\n"
     ]
    }
   ],
   "source": [
    "amostra_eda = 5000\n",
    "radicais = tweets_full.sample(amostra_eda)['tweet_text'].progress_apply(preprocessing_full)\n",
    "\n",
    "tweets = tweets_full.copy()\n",
    "tweets['radicais'] = radicais\n",
    "tweets = tweets[tweets.radicais.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>query_used</th>\n",
       "      <th>radicais</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1049278847697539072</th>\n",
       "      <td>@nocedanielle Me diz pelo menos que a m√£e do P...</td>\n",
       "      <td>2018-10-08 12:42:26+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "      <td>mae paulo nao votar fascista amar senhor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049262635458473990</th>\n",
       "      <td>Meu est√¥mago t√° doendo :(</td>\n",
       "      <td>2018-10-08 11:38:01+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "      <td>estomagar ta doer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049172777822040065</th>\n",
       "      <td>t√£o linda o anjinho :( üíñ https://t.co/HP06XriVMT</td>\n",
       "      <td>2018-10-08 05:40:57+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "      <td>tao lindo anjo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047394155700387840</th>\n",
       "      <td>@RodrigoRebesch Feliz anivers√°rio. N√£o fica fo...</td>\n",
       "      <td>2018-10-03 07:53:21+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>:)</td>\n",
       "      <td>feliz aniversariar nao ficar focar mensagem mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049164521233948672</th>\n",
       "      <td>@hobimysavior Fico muito triste em ver o meu p...</td>\n",
       "      <td>2018-10-08 05:08:09+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "      <td>ficar triste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046768209221816321</th>\n",
       "      <td>o cabelo dela :( https://t.co/it5ClnOlKW</td>\n",
       "      <td>2018-10-01 14:26:03+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "      <td>cabelar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042557710103977985</th>\n",
       "      <td>Haddad quer manter regime de atua√ß√£o do Banco ...</td>\n",
       "      <td>2018-09-19 23:35:02+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>folha</td>\n",
       "      <td>haddad manter regime atuacao banco central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050779816885149696</th>\n",
       "      <td>@kauannefelicio Sei n√£o ein.... voc√™ e Ester T...</td>\n",
       "      <td>2018-10-12 16:06:45+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>:)</td>\n",
       "      <td>nao ein voce ester tigre dificil lindo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047554378779881472</th>\n",
       "      <td>Menina que tentou matar os pais com veneno no ...</td>\n",
       "      <td>2018-10-03 18:30:01+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>g1</td>\n",
       "      <td>menino tentar matar pai veneno cafe querer mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046775171485507584</th>\n",
       "      <td>@423JE sou sim :(</td>\n",
       "      <td>2018-10-01 14:53:43+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>:(</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            tweet_text  \\\n",
       "id                                                                       \n",
       "1049278847697539072  @nocedanielle Me diz pelo menos que a m√£e do P...   \n",
       "1049262635458473990                          Meu est√¥mago t√° doendo :(   \n",
       "1049172777822040065   t√£o linda o anjinho :( üíñ https://t.co/HP06XriVMT   \n",
       "1047394155700387840  @RodrigoRebesch Feliz anivers√°rio. N√£o fica fo...   \n",
       "1049164521233948672  @hobimysavior Fico muito triste em ver o meu p...   \n",
       "1046768209221816321           o cabelo dela :( https://t.co/it5ClnOlKW   \n",
       "1042557710103977985  Haddad quer manter regime de atua√ß√£o do Banco ...   \n",
       "1050779816885149696  @kauannefelicio Sei n√£o ein.... voc√™ e Ester T...   \n",
       "1047554378779881472  Menina que tentou matar os pais com veneno no ...   \n",
       "1046775171485507584                                  @423JE sou sim :(   \n",
       "\n",
       "                                   tweet_date sentiment query_used  \\\n",
       "id                                                                   \n",
       "1049278847697539072 2018-10-08 12:42:26+00:00         0         :(   \n",
       "1049262635458473990 2018-10-08 11:38:01+00:00         0         :(   \n",
       "1049172777822040065 2018-10-08 05:40:57+00:00         0         :(   \n",
       "1047394155700387840 2018-10-03 07:53:21+00:00         1         :)   \n",
       "1049164521233948672 2018-10-08 05:08:09+00:00         0         :(   \n",
       "1046768209221816321 2018-10-01 14:26:03+00:00         0         :(   \n",
       "1042557710103977985 2018-09-19 23:35:02+00:00         2      folha   \n",
       "1050779816885149696 2018-10-12 16:06:45+00:00         1         :)   \n",
       "1047554378779881472 2018-10-03 18:30:01+00:00         2         g1   \n",
       "1046775171485507584 2018-10-01 14:53:43+00:00         0         :(   \n",
       "\n",
       "                                                              radicais  \n",
       "id                                                                      \n",
       "1049278847697539072           mae paulo nao votar fascista amar senhor  \n",
       "1049262635458473990                                  estomagar ta doer  \n",
       "1049172777822040065                                     tao lindo anjo  \n",
       "1047394155700387840  feliz aniversariar nao ficar focar mensagem mi...  \n",
       "1049164521233948672                                       ficar triste  \n",
       "1046768209221816321                                            cabelar  \n",
       "1042557710103977985         haddad manter regime atuacao banco central  \n",
       "1050779816885149696             nao ein voce ester tigre dificil lindo  \n",
       "1047554378779881472  menino tentar matar pai veneno cafe querer mor...  \n",
       "1046775171485507584                                                     "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento de modelos\n",
    "\n",
    "Vamos agora testar v√°rios modelos de aprendizado de m√°quina, comparando-os para escolher o melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepara√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets['radicais'] + ' ' + tweets['query_used'] # conforme dito na fase de An√°lise Explorat√≥ria\n",
    "y = tweets['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size = 0.3,\n",
    "    stratify = y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defini√ß√£o do *pipeline*\n",
    "\n",
    "Vamos montar um *pipeline* de processamento do `scikit-learn`. Dessa forma, podemos automatizar o processo de otimiza√ß√£o de hiperpar√¢metros ap√≥s a escolha do melhor modelo.\n",
    "\n",
    "Um *pipeline* √© composto de um ou mais *transformers* e um estimador ao final. Os *transformers* tem como fun√ß√£o transformar os dados, de forma que eles possam ser usados como entrada para um estimador, que usar√° os dados para fazer estimativas.\n",
    "\n",
    "No nosso caso, a nossa *pipeline* ser√° composta de um *transformer* e um estimador, detalhados a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defini√ß√£o dos *Transformers*\n",
    "\n",
    "No nosso caso, os *transformers* ter√£o como *input* os *tweets* j√° pr√©-processados (mas ainda em formato de texto), e ter√£o como sa√≠da uma s√©rie de *features* num√©ricas.\n",
    "\n",
    "Testaremos 4 *transformers* diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_transformers = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Bag of Words* (`CountVectorizer`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow = CountVectorizer()\n",
    "\n",
    "pipeline_transformers['bow'] = bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Bag of Words* - TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(use_idf=True)\n",
    "\n",
    "pipeline_transformers['tfidf'] = tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Word2Vec***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltoolkit.NLP import W2VTransformer\n",
    "\n",
    "word2vec = W2VTransformer(\n",
    "    vector_size = 50,\n",
    "    min_count = 2,\n",
    "    workers = 2\n",
    ")\n",
    "\n",
    "pipeline_transformers['word2vec'] = word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Doc2Vec***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltoolkit.NLP import D2VTransformer\n",
    "\n",
    "doc2vec = D2VTransformer(\n",
    "    vector_size = 50,\n",
    "    min_count = 2,\n",
    "    workers = 2\n",
    ")\n",
    "\n",
    "pipeline_transformers['doc2vec'] = doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defini√ß√£o dos estimadores\n",
    "\n",
    "Os estimadores s√£o os diferentes modelos de aprendizado de m√°quina, que utilizaremos para predizer o tom (sentimento) de um *tweet* qualquer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# para reproducibilidade\n",
    "random_seed = 42\n",
    "\n",
    "pipeline_estimadores = {\n",
    "    'logistic': LogisticRegression(random_state = random_seed),\n",
    "    'random_forest': RandomForestClassifier(random_state = random_seed),\n",
    "    'adaboost': AdaBoostClassifier(random_state = random_seed),\n",
    "    'xgboost': XGBClassifier(random_state = random_seed, eval_metric = 'logloss', use_label_encoder = False),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepara√ß√£o do *pipeline*\n",
    "\n",
    "Vamos agora cruzar cada *transformer* com cada estimador, e rodar os *pipelines* resultantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipelines = {}\n",
    "\n",
    "# construindo as pipelines\n",
    "for nome_transformer, transformer in pipeline_transformers.items():\n",
    "    for nome_estimador, estimador in pipeline_estimadores.items():\n",
    "        pipelines[f'{nome_estimador}.{nome_transformer}'] = Pipeline(steps = [\n",
    "            (nome_transformer, deepcopy(transformer)),\n",
    "            (nome_estimador, deepcopy(estimador))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pipeline:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 8/16 [00:04<00:04,  1.69it/s]E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Pipeline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:19<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "# rodando as pipelines\n",
    "for nome_pipeline, pipeline in tqdm(pipelines.items(), desc = 'Pipeline'):\n",
    "    nome_estimador, nome_transformer = nome_pipeline.split('.')\n",
    "    pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost.doc2vec\n"
     ]
    }
   ],
   "source": [
    "print(nome_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.66       494\n",
      "           1       0.67      0.74      0.70       502\n",
      "           2       0.99      0.99      0.99       504\n",
      "\n",
      "    accuracy                           0.79      1500\n",
      "   macro avg       0.79      0.79      0.79      1500\n",
      "weighted avg       0.79      0.79      0.79      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vamos ver se funcionou...\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "est = pipelines['xgboost.tfidf']\n",
    "\n",
    "y_pred = est.predict(X_test)\n",
    "\n",
    "print(classification_report(\n",
    "    y_true = y_test,\n",
    "    y_pred = y_pred\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medi√ß√£o de desempenho\n",
    "\n",
    "Vamos agora ver como o desempenho de cada combina√ß√£o de modelo com *transformer* se compara com os demais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Medindo desempenho:  12%|‚ñà‚ñé        | 2/16 [00:00<00:01,  9.20it/s]E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Medindo desempenho:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [00:00<00:00, 10.69it/s]E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Medindo desempenho: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:03<00:00,  4.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "\n",
    "# construindo um dataframe com as m√©tricas relevantes\n",
    "\n",
    "model_rank_name = pd.Series(pipelines.keys()).str.split('.')\n",
    "model_rank_name = pd.DataFrame(model_rank_name.to_list(), columns = ['estimador', 'transformer'])\n",
    "model_rank_idx = pd.MultiIndex.from_frame(model_rank_name)\n",
    "\n",
    "model_rank = pd.DataFrame([], index = model_rank_idx)\n",
    "\n",
    "for nome_pipeline, pipeline in tqdm(pipelines.items(), desc = 'Medindo desempenho'):\n",
    "    nome_estimador, nome_transformer = nome_pipeline.split('.')\n",
    "\n",
    "    # gerando a predi√ß√£o\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_predproba = pipeline.predict_proba(X_test)\n",
    "    \n",
    "    # dicion√°rio com argumentos de todas as fun√ß√µes\n",
    "    kwargs = dict(y_true = y_test.astype(int), y_pred = y_pred.astype(int))\n",
    "\n",
    "    # calculando as m√©tricas\n",
    "    acc = accuracy_score(**kwargs)\n",
    "    precision = precision_score(average = 'weighted', **kwargs)\n",
    "    recall = recall_score(average = 'weighted', **kwargs)\n",
    "    f1 = f1_score(average = 'weighted', **kwargs)\n",
    "    logloss = log_loss(y_true = y_test, y_pred = y_predproba)\n",
    "\n",
    "    # registrando as m√©tricas no dataframe\n",
    "    model_rank.loc[(nome_estimador, nome_transformer), 'accuracy'] = acc\n",
    "    model_rank.loc[(nome_estimador, nome_transformer), 'precision'] = precision\n",
    "    model_rank.loc[(nome_estimador, nome_transformer), 'recall'] = recall\n",
    "    model_rank.loc[(nome_estimador, nome_transformer), 'f1'] = f1\n",
    "    model_rank.loc[(nome_estimador, nome_transformer), 'neg_log_loss'] = -logloss\n",
    "\n",
    "model_rank.sort_values(by = ['f1', 'accuracy'], ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>neg_log_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estimador</th>\n",
       "      <th>transformer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <th>word2vec</th>\n",
       "      <td>94.73%</td>\n",
       "      <td>94.73%</td>\n",
       "      <td>94.73%</td>\n",
       "      <td>94.71%</td>\n",
       "      <td>-37.71%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <th>word2vec</th>\n",
       "      <td>82.80%</td>\n",
       "      <td>82.91%</td>\n",
       "      <td>82.80%</td>\n",
       "      <td>82.83%</td>\n",
       "      <td>-58.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <th>word2vec</th>\n",
       "      <td>82.20%</td>\n",
       "      <td>82.30%</td>\n",
       "      <td>82.20%</td>\n",
       "      <td>82.23%</td>\n",
       "      <td>-42.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">logistic</th>\n",
       "      <th>tfidf</th>\n",
       "      <td>81.00%</td>\n",
       "      <td>81.08%</td>\n",
       "      <td>81.00%</td>\n",
       "      <td>80.99%</td>\n",
       "      <td>-54.45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bow</th>\n",
       "      <td>80.67%</td>\n",
       "      <td>80.69%</td>\n",
       "      <td>80.67%</td>\n",
       "      <td>80.66%</td>\n",
       "      <td>-46.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">xgboost</th>\n",
       "      <th>bow</th>\n",
       "      <td>79.47%</td>\n",
       "      <td>79.82%</td>\n",
       "      <td>79.47%</td>\n",
       "      <td>79.27%</td>\n",
       "      <td>-41.79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>78.73%</td>\n",
       "      <td>78.83%</td>\n",
       "      <td>78.73%</td>\n",
       "      <td>78.62%</td>\n",
       "      <td>-43.08%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">random_forest</th>\n",
       "      <th>bow</th>\n",
       "      <td>78.40%</td>\n",
       "      <td>78.32%</td>\n",
       "      <td>78.40%</td>\n",
       "      <td>78.35%</td>\n",
       "      <td>-54.80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>78.00%</td>\n",
       "      <td>77.87%</td>\n",
       "      <td>78.00%</td>\n",
       "      <td>77.84%</td>\n",
       "      <td>-48.93%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">adaboost</th>\n",
       "      <th>word2vec</th>\n",
       "      <td>65.93%</td>\n",
       "      <td>66.84%</td>\n",
       "      <td>65.93%</td>\n",
       "      <td>65.89%</td>\n",
       "      <td>-107.71%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>59.40%</td>\n",
       "      <td>48.40%</td>\n",
       "      <td>59.40%</td>\n",
       "      <td>50.05%</td>\n",
       "      <td>-72.89%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bow</th>\n",
       "      <td>55.40%</td>\n",
       "      <td>47.65%</td>\n",
       "      <td>55.40%</td>\n",
       "      <td>46.61%</td>\n",
       "      <td>-74.79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <th>doc2vec</th>\n",
       "      <td>47.60%</td>\n",
       "      <td>47.11%</td>\n",
       "      <td>47.60%</td>\n",
       "      <td>46.51%</td>\n",
       "      <td>-102.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost</th>\n",
       "      <th>doc2vec</th>\n",
       "      <td>45.40%</td>\n",
       "      <td>45.23%</td>\n",
       "      <td>45.40%</td>\n",
       "      <td>45.06%</td>\n",
       "      <td>-121.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost</th>\n",
       "      <th>doc2vec</th>\n",
       "      <td>43.80%</td>\n",
       "      <td>42.58%</td>\n",
       "      <td>43.80%</td>\n",
       "      <td>41.61%</td>\n",
       "      <td>-108.12%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <th>doc2vec</th>\n",
       "      <td>43.33%</td>\n",
       "      <td>42.42%</td>\n",
       "      <td>43.33%</td>\n",
       "      <td>40.57%</td>\n",
       "      <td>-104.83%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           accuracy  precision  recall     f1  neg_log_loss\n",
       "estimador     transformer                                                  \n",
       "logistic      word2vec       94.73%     94.73%  94.73% 94.71%       -37.71%\n",
       "random_forest word2vec       82.80%     82.91%  82.80% 82.83%       -58.01%\n",
       "xgboost       word2vec       82.20%     82.30%  82.20% 82.23%       -42.01%\n",
       "logistic      tfidf          81.00%     81.08%  81.00% 80.99%       -54.45%\n",
       "              bow            80.67%     80.69%  80.67% 80.66%       -46.03%\n",
       "xgboost       bow            79.47%     79.82%  79.47% 79.27%       -41.79%\n",
       "              tfidf          78.73%     78.83%  78.73% 78.62%       -43.08%\n",
       "random_forest bow            78.40%     78.32%  78.40% 78.35%       -54.80%\n",
       "              tfidf          78.00%     77.87%  78.00% 77.84%       -48.93%\n",
       "adaboost      word2vec       65.93%     66.84%  65.93% 65.89%      -107.71%\n",
       "              tfidf          59.40%     48.40%  59.40% 50.05%       -72.89%\n",
       "              bow            55.40%     47.65%  55.40% 46.61%       -74.79%\n",
       "random_forest doc2vec        47.60%     47.11%  47.60% 46.51%      -102.57%\n",
       "xgboost       doc2vec        45.40%     45.23%  45.40% 45.06%      -121.00%\n",
       "adaboost      doc2vec        43.80%     42.58%  43.80% 41.61%      -108.12%\n",
       "logistic      doc2vec        43.33%     42.42%  43.33% 40.57%      -104.83%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.float_format', lambda x: f'{x:.2%}'):\n",
    "    display(model_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que \n",
    "* o *transformer* ***Word2Vec*** performa muito bem nessa base: as tr√™s melhores combina√ß√µes usam esse *transformer*; e\n",
    "* especificamente, **o modelo de regress√£o log√≠stica com *transformer* *Word2Vec* performou de forma excelente** no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'logistic', transformer 'word2vec':\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       494\n",
      "           1       0.94      0.96      0.95       502\n",
      "           2       0.95      0.91      0.93       504\n",
      "\n",
      "    accuracy                           0.95      1500\n",
      "   macro avg       0.95      0.95      0.95      1500\n",
      "weighted avg       0.95      0.95      0.95      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_pipeline = 'logistic.word2vec'\n",
    "nome_estimador, nome_transformer = nome_pipeline.split('.')\n",
    "est = pipelines[nome_pipeline]\n",
    "\n",
    "y_pred = est.predict(X_test)\n",
    "\n",
    "print(f\"Modelo '{nome_estimador}', transformer '{nome_transformer}':\")\n",
    "print(classification_report(\n",
    "    y_true = y_test,\n",
    "    y_pred = y_pred\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'logistic', transformer 'word2vec':\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAycAAAMrCAYAAABTa+3SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAABJ0AAASdAHeZh94AAA+ZUlEQVR4nO3dZ5hU9d3/8c/SBRQURSSimKARRMXeYqwoYIXEQjRGU0zs3TuiCIIkxt6CxhJLEI09MbYYe2zRaPQGjLeoYAsiqyIgRWD/D/y7yQYsrAvzA16v69oHc86Zw3fmctx9z5lzpqqmpqYmAAAAFdao0gMAAAAk4gQAACiEOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCE0qPcDC9MEHH+Thhx9Op06d0rx580qPAwAAS42ZM2fmjTfeyDbbbJO2bdt+qfss0XHy8MMPZ88996z0GAAAsNS6/fbbs8cee3ypbZfoOOnUqVOSpMkafdKoeZsKTwM0lMeuH1DpEYCFoKbSAwAN6pVXxqb/d/vW/k3+ZSzRcfLpR7kaNW+TRsu0q/A0QEPp1m2dSo8ALATiBJZMC3J6hRPiAQCAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4oTiHbjnFpn+7EV5969nz7PuoL5b5rHrTsg7j5yZNx84I3++/Mj0+tY682x3+Pe2zQ1n/zgv3jE405+9KPdeduSiGB1YQI88/FBaNW8035+/PfVkpccDvoLn//Fc9v1u33Tp/LWs1LZVNli3a345bEg++uijSo9GQYqLk6lTp+boo49Ox44d06JFi/To0SM33HBDpceiQjqu1Ca/PGbPvD3xg3nWDfxZnwwf2D/PjBqf/idcmYMHj8jMWbNz24U/yx7br19n2x9/51vptMryeejp/8vE96YsoumB+ho8dFgefOTxOj/d1ule6bGAenrxxTHZYZutMn78uPzq7PNy02135Lt775Mzhg3NQd//XqXHoyBNKj3Af+vXr1+efvrpnHHGGVlrrbUycuTI9O/fP3Pnzs33vuc/3qXNhSfvk78++0ren/xR+u7Yo866H+yxeR577pUc9csba5fd/+Q/M+6+Ydlv103zhweer12+wXeHpaamJknyzI0nLZLZgfrr0mXNbLrZ5pUeA2ggN94wMjNmzMh1N9ycr3/jG0mSbbfbPhP+9a9cdeXlef/997P88stXeEpKUNSRk7vuuiv33Xdfhg8fnp/+9KfZbrvtcvnll6dnz5454YQTMmfOnEqPyCK0b5+Ns/WGXXL0f8THf/p49txMnjq9zrKZs2ZnxszZmTlrdp3ln4YJALDoNW3aNEmyXJs2dZa3bds2jRo1SrNmzSoxFgUqKk5uu+22tG7dOnvttVed5QcddFDefvvtPPXUUxWajEVtpeVb56zjvpOBF92Rt+bzka4k+fX1D2WnLbrmB3tsnrbLLpMOKy6XXx3bN21at8jw6x9apPMCDeuYow7Pci2bpsOKbbL7Lr3y+GN/rfRIwFew3/4/SNu2bXP0EYfmtVdfzZQpU3L3nX/Kb6+4LAf/7NC0atWq0iNSiKI+1jVq1Kh07do1TZrUHWu99darXb/llltWYjQWsQtO2jsvj5+Yy2569DO3uXjkQ5k+8+Oc//O9c+mg/ZIk1R9My3eOvixPPP/aohoVaEDLtWmTQw8/Mt/+9rZZoV27vPLK2Fxw7tnp1XO73HL7n9Jzp50rPSJQD6t37pz7H348/fful3W7dqldfshhR+TMc86v3GAUp6g4qa6uzte//vV5lq+wwgq16z/LxIkT8+6779ZZNnbs2IYdkEViz+3XT59vd8/m/c/83O2+v/tmOfv47+TS3z+Sex8fk2ZNmmS/XTfNTef9JPsef0X+8sQ/F9HEQEPp0WOD9OixQe3trb61dXbfo2823Wi9nDLgf8QJLKbGjxuXvfvtnvYrr5wRN9yUFVdcKc/87amcecawTJs2NcN/c2WlR6QQRcVJklRVVdVr3fDhw3PaaactjJFYhFot0yzn/XzvXHLDI/nXu5PTpvUySZJmTRsnSdq0XiYfz56TZk0b5/z/2TtX3/5ETjr/9tr7//nxMbn3siNz0YB903W3wRV4BEBDa9u2bXr33iVXXP6bTJ8+Pcsss0ylRwIW0KmnnJQPp3yYx59+rvYjXN/a+ttpt+KKOeTgH6X/fgdk629vU+EpKUFRcdKuXbv5Hh157733kvz7CMr8HHroofOcqzJ27NjsueeeDTojC1e7tq3TYcXlcvQBO+ToA3aYZ/2ER87MHQ++kLOvvi8tl2mWZ0aPn2ebZ8e8nm9vvGZaLdMs06bPWhRjAwvZpxe1+Lw3qYByvfD8P7J2127znFuy4cabJEnGjB4lTkhSWJysu+66uf766zN79uw655387//+b5Kke/fPvsZ9+/bt0759+4U+IwvXO9UfZqefXDDP8uMP6pmtN+ySPY64JNUfTMuUaTOSJJuu2znX/elvdbbddN3OeW/yNGECS4j3338/d999Z9Zbv0datGhR6XGAelilY8eMGT0qU6dOTevWrWuX/+3JJ5IkX/vaqpUajcIUFSd9+/bN5ZdfnltuuSX77LNP7fJrrrkmHTt2zGabbVbB6VgUZs6anUf/Pu+5Qt/fbfPMmVtTZ93t9/8jP+q3VWZ9PDv3/HVMmjdrkv133TRbbvCNDP71n+rcf8OunbJ6x3ZJkuVatUhVVVX67tAjSfL3MePz+r/eX3gPCvjSDjxgv3Tq1CkbbrRx2rVbMa+MfTkXnn9uJr7zTn5z+VWVHg+op8MOPyr77tU3u/fZKYcdeXTatVsxT//tyZxz5hlZu2u37NSrd6VHpBBFxUnv3r3Ts2fPHHLIIfnwww/TpUuXXH/99bnnnnsyYsSING7cuNIjUpADT74mh+zz7fTfZdMcsPvm+Xj23Ix9fWIOOvma3HD3M3W2/dk+2+T7u9eN25Fn/ShJ8pNBIzLiDpephhJ0X3fd3HLTjbny8t9k6tSpWX6FFbLllt/KFVddm43+/8c/gMXPLrvtnj/d85ece9avcuJxR+fDyZOz6qqd8sMfH5zjTjzJ95xQq6qmsG+nmzp1ak4++eTceOONee+997L22mvnpJNOyr777rvA+xo9enS6d++eZmv3T6Nl2i2EaYFKqH7ywkqPACwERf1BAnxlY8aMzqYbrJtRo0ZlnXXW+VL3KerISZK0bt06F1xwQS64YN7zDgAAgCVXUd8QDwAALL3ECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUoUmlB1gUnrjh5HRbZ51KjwE0kOU3ObzSIwALwb8ev6DSIwANaPacuQt8H0dOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCE0WZOMhQ4Z86W2rqqoycODABR4IAABYOi1QnAwePPhLbytOAACABbFAcTJ37tyFNQcAALCUc84JAABQhAU6cjI///znP/Pwww9n0qRJ+dGPfpQOHTrk7bffzvLLL59lllmmIWYEAACWAvWOkzlz5uTggw/O1VdfnZqamlRVVaV3797p0KFDfvrTn2aDDTZYoBPoAQCApVu9P9Y1bNiwjBw5MmeddVZGjRqVmpqa2nW9e/fOPffc0yADAgAAS4d6Hzm5+uqrM3DgwBx77LGZM2dOnXVrrLFGXnvtta88HAAAsPSo95GTt956K1tsscV817Vo0SJTpkyp91AAAMDSp95x0r59+7z66qvzXffSSy9l1VVXrfdQAADA0qfecdKnT58MGzYsb731Vu2yqqqqTJ48ORdeeGF22223BhkQAABYOtQ7ToYMGZLZs2enW7du+c53vpOqqqoMGDAg3bt3z4wZM3w7PAAAsEDqHScrr7xynn766fTv3z9///vf07hx4zz//PPp3bt3Hn/88aywwgoNOScAALCE+0pfwrjyyivn0ksvbahZAACApdhX/ob4JHn77bdTXV2ddu3apWPHjg2xSwAAYClT7491Jcmtt96ab37zm+nUqVN69OiRTp06Za211srNN9/cUPMBAABLiXrHye9///t897vfTePGjXPqqadm+PDhGThwYBo3bpx99tknv//97xtyTgAAYAlX7491DRkyJL17984dd9yRRo3+3TinnnpqdtlllwwZMiT77LNPgwwJAAAs+ep95OSVV17JoYceWidMkqRRo0Y59NBD88orr3zl4QAAgKVHveNk9dVXz0cffTTfdR999FE6depU76EAAIClT73j5LjjjsuQIUMyadKkOssnTpyY008/Pccff/xXHg4AAFh6LNA5J0ceeWSd2x9++GE6d+6cHXbYIR06dMiECRNy//33Z8UVV8yYMWMadFAAAGDJtkBxcvHFF893+R133FHn9uuvv56LL744F1xwQf0nAwAAlioLFCdz585dWHMAAABLua/0JYwAAAANRZwAAABF+EpxMmLEiGy88cZp1apVGjduPM8PAADAl1XvOPnjH/+Ygw46KBtssEGmT5+egw46KP3790+rVq2y5ppr5tRTT23IOQEAgCVcvePkjDPOyLHHHptLL700SXLooYdmxIgR+b//+7/MmTPHlzACAAALpN5x8tJLL2XHHXdMVVVVkmT27NlJkg4dOuSUU07Jueee2zATAgAAS4V6x8mcOXPSrFmzNGrUKK1atcqECRNq16222mp59dVXG2RA+DxTpkzJgJ+fmF1775ROq6yUZZpW5fQhgys9FvAFDuy7RaY/d3HefeycedYd1HfLPHbdiXnn0bPy5oO/yp+vOCq9vrVOnW1atmiWa884KM/fNjAT/3p2Jj1+Tv5+88n5nx/vnJYtmi2qhwHMx5QpU3Lqyf+Tfrv1SpfVOmT5lk1yxumnzbNdTU1NrvntFdl2y02z2srL5+urts8uO22Xe+++swJTU4p6x8kaa6yRt99+O0my/vrr5/rrr69dd/PNN2eVVVb56tPBF3ivujq/veKyzJw5M7vtvmelxwG+hI4rtckvj+mbtyd+MM+6gYfskuGnfi/PjB6f/sdfmYMH/S4zZ83ObRcdkj22X792u6ZNGqcqyYUjHkj/46/IXsdcltvv/0cGHNw7N51/8KJ7MMA83n+vOtf89orMnDkzu+y6x2du98uhg3P04T/LhhtvkmtG3phf/+bKNG/ePPt+Z4/ccftti3BiSrJAX8L4n3bYYYf85S9/Sf/+/XPUUUdln332ydNPP51mzZrlpZdeyhlnnFGv/U6ZMiVDhw7NP/7xjzz33HOZNGlSBg0alMGDB9d3VJZgq62+ev717vupqqrKpEmTctVvr6j0SMAXuPDkffPXZ1/J+5Onpe+OG9RZ94M9Ns9jz47NUb/4fe2y+5/8Z8b95RfZb7fN8ocHnk+STJ46Pd//+VV17vvgUy+ledMmOe6gnun8tXYZ91b1wn8wwDw6rbZ6xr09KVVVVameNCnXXn3lfLe77tqrs/mWW+XcC39du2y7HXrmm2t8Lddfd21227PvohqZgtT7yMmwYcNy3nnnJUn22muv3HzzzVl//fXTrVu3XHnllTnhhBPqtd/q6upcdtkn74Tvueee9R2PpURVVVXteU9A+fbts0m23qhLjv6P+PhPH8+ek8lTZ9RZNnPW7MyYOTszZ378hfuf9P7UJMmcOXO/+rBAvXzZ381NmjbNcsu1qbOsRYsWadG8RVq0aLGwxqNw9T5y0rx58zRv3rz2dr9+/dKvX7+vPNDqq6+e99//9zvhV1zhnXCAJcFKy7fOWcd/JwMv/GPems9HupLk1yMfyi+P6Zsf7LlF/nD/P9KiedMc84Md06Z1iwy//uH53qdx40Zp2aJZNl9/jRz5/e3z+7ufyRsT3l+IjwRoCD877IgMPOnE/O7q32a3PfpmxowZuej8s/Phh5Nz8KGHV3o8KqTecbKweBccYMl0wYB98vL4d3LZTY9+5jYXj3wo02d+nPN/vncuHbRfkqT6g2n5ztG/yRPPz3uhlb123ijXnnFQ7e1rbn8ih51+/TzbAeU55PCj0qLFMjnhmCNy5KGfnCu2/Aor5Pqbb8/mW2xV4emolAWKkx/+8IdfetuqqqpceeX8P2O4MEycODHvvvtunWVjx45dZP8+AJ9tzx16pM+3u2fz/r/63O2+v/vmOfuE7+bS3z+Sex8bnWZNm2S/XTfNTecdnH2PuyJ/eeLFOtvf9/iYbLXfmWndsnk2W2+NHHdgz6zQtlX2Ofby1NTULMyHBHxF1117dU464Zj85GeHZsedemXWrFm5YeSI7Ld3v1x7/U3ZoefOlR6RCligOHnggQe+9JGNRX0EZPjw4TnttHkvUwdAZbVaplnO+/neueSGR/KviZPTpvUySZJmTT/5FdSm9TL5ePacNGvaOOf/fO9cfdvjOem8f1+p58+Pjcm9lx+Vi07eJ113HVxn3x9MmZ5nx7yeJHnkmZfz2puT8rtf/TC7bbtu/vjgC4vmAQIL7IP3388JxxyR7x/4owz95Vm1y3vu3Du77rx9jj3ysDz/ojeZl0YLFCfjxo1bSGN8dYceemj22muvOsvGjh3rpHqACmvXtnU6rLhcjj5ghxx9wA7zrJ/w6Fm548Hnc/ZV96XlMs3yzP+Pjf/07JjX8+2N10yrZZpl2vRZn/lvPT1qfJJkzdXbN9wDABrcyy+/lOnTp2fDjTaeZ90GG26Uxx59JFOnTk3r1q0rMB2VVNw5J/XVvn37tG/vlxFAad6p/jA7/fiCeZYff1DPbL1Rl+xx+CWp/mBqpkz75Cpdm67bOdfd8VSdbTddt3Pemzztc8MkSbbZZM0kyStvTGqg6YGFocMqHZMkT//tqfTf/4Da5TU1NXn6b0+l7fLLp1WrVpUajwpaYuKEpde999ydadOmZeqUKUmSF18ck1tvuTlJ0qt3n7Rs2bKS48FSb+as2Xn07y/Ps/z7u2+WOXNr6qy7/f5/5Ef9tsqsWbNzz19Hp3mzJtl/t82y5QbfyOBf31G73Y++s1W22uAb+cuT/8ybE95Pq2WaZ6sNvpFD9t0mT/zjldzxkI90QSXdd+/d+eijj2p/N7/0zxfzh9tuSfLJR7c6dVotu+3RN9f89vI0b948PXfulZkzZ+aG636Xp554PCefepqLJC2lxAmLvSMPPySvjx9fe/vWm2/KrTfflCT558uvZfXOnSs0GbCgDhxwdQ7ZZ5v033WTHLDH5vl49tyMfX1iDhpwdW64+5na7UaPfTu9t+6eoUfsnnZtW2X2nLkZ+/q7OfO39+bCEQ/4nhOosOOOOjxvvP7v382333pzbr/1kzcOn39xbFZbvXMuu+p3ufzSX+f311+X6669Kk2aNk2XLmvmN7+9Nnvt079So1NhVTUFXs7k7rs/eSd8ypQp+eEPf5i99tore++9d5KkT58v/0746NGj07179/z9H6PSbZ11FubIwCK0/Caufw9Lon89Pu/H/4DF14tjRmfLjdfPqFGjss6X/Fu8yCMnhxxySMb/xzvhN910U2666ZN3wl977bV09k44AAAscYqMk5KvCgYAACwcXzlOJk+enCeffDKTJk1Knz59svzyyzfEXAAAwFKm0Ve589ChQ9OxY8f07t07BxxwQF577bUkyQ477JAzzjijQQYEAACWDvWOk0+/kf1HP/pR7rzzzvznefW77rpr7rzzzgYZEAAAWDrU+2NdF198cY499ticeeaZmTNnTp11a665Zl5+ed5r2gMAAHyWeh85efXVV7PzzjvPd92yyy6bDz74oL67BgAAlkL1jpM2bdrknXfeme+6cePGpX379vUeCgAAWPrUO0522GGHnHnmmZk2bVrtsqqqqsyePTuXXHLJZx5VAQAAmJ96n3MyZMiQbLLJJunWrVv69u2bqqqqXHzxxXnuuefy+uuv58Ybb2zIOQEAgCVcvY+cdOnSJY899li6du2a4cOHp6amJtdee21WXHHFPProo1lttdUack4AAGAJ95W+hLFbt2655557MnPmzFRXV2f55ZfPMsss01CzAQAAS5Gv/A3xSdK8efN07NixIXYFAAAspb7SOSefp6qqKgMHDqzv7gEAgKVMveNk8ODBn7tenAAAAAui3ifEz507d56fSZMm5Yorrkj37t0zbty4BhwTAABY0tU7TuZnhRVWyA9/+MN873vfy5FHHtmQuwYAAJZwDRonn9p0001z//33L4xdAwAAS6iFEifPP/98WrduvTB2DQAALKHqfUL8tddeO8+ymTNn5oUXXshvf/vb7L///l9pMAAAYOlS7zg58MAD57u8RYsW2X///XP22WfXd9cAAMBSqN5x8tprr82zrEWLFll55ZW/0kAAAMDSqV5xMmPGjPzmN7/Jd77znWy00UYNPRMAALAUqtcJ8S1atMh5552XadOmNfQ8AADAUqreV+vq2rXrfD/aBQAAUB/1jpOBAwfm9NNPzyuvvNKQ8wAAAEupep8Qf9VVV+Wjjz5K165ds95662WVVVZJVVVV7fqqqqr84Q9/aJAhAQCAJV+94+SFF15Is2bN8rWvfS3V1dWprq5uyLkAAIClTL3jZNy4cQ04BgAAsLSr9zknjzzySKZOnTrfddOmTcsjjzxS76EAAIClT73jZLvttsuYMWPmu+6f//xntttuu3oPBQAALH3qHSc1NTWfue7jjz9Oo0b13jUAALAUWqBzTj788MN88MEHtbcnTJiQ119/vc4206dPzzXXXJMOHTo0yIAAAMDSYYHi5LzzzsuQIUOSfHKp4L59+853u5qamgwYMOCrTwcAACw1FihOdtppp7Ru3To1NTU58cQTc8QRR2S11Vars03z5s2z7rrrZptttmnQQQEAgCXbAsXJFltskS222CLJJ1fk+slPfpKOHTsulMEAAIClS72/52TQoEENOQcAALCUc0ktAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCI0qfQAi8LMj+dkxqw5lR4DaCBv/vX8So8ALASr7Dyk0iMADWjutIkLfB9HTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAoQpNKDwBfxiMPPZAbbxiZvz31RN568420adM2PTbcKCeedEp6bLBR7XZPPP7XXD/i2rzw/D/y4phRmTVrVp4fMzarrd65csMD8/XIQw/m5t9fl789+WTefuuNLPf/X9fH//zkOq/rJPn4449z+aUX5/rfXZPXXn0lzZo3zzfX7prThv0qm26+ZYUeAfDfDtxlw1zyP3tk6kczs1KvX9Quv+ykPfP93hvMs/1L499Nj+9fXHt7/149cvmAvp+5/4G/uS9nX/fXhh2aoogTFgu/veI3ea+6Oj899IisvXbXTJo0Kb++8Nz03Har3PKHu/LtbbdP8knEPPTg/Vlv/R5Zdrll89dHHq7w5MBnufqK3+S996pz8KGH55trd0v1pHcz/KLz0mu7b+XG2+/Kt7fdLkkyZ86cHND/u3nqicdyxNHHZ5PNtshHH03L8889m48++qjCjwL4VMcVl80vD90pb7/7YZZr1Xye9R/NmJXeR19TZ9n0mR/XuX3PE/+XbX52+Tz3Hfij7bLjJl3yh0debNihKU5RcfLAAw9kxIgRefzxx/PGG2+kbdu22XjjjXPqqadmo402+uIdsMQ669yLslL79nWW7dBz52y07jdz7lln1MbJCT8/Jf8z4NQkyUXnnyNOoGC/OvfCeV7X2/fcOZuut3bOP/uM2ji5/NKLc/+f78ldf3k4G2+6ee22O/Xqs0jnBT7fhcftlr++MD7vfzg9fbfpNs/6uXNr8rcxb37uPiZN/iiTJtd906Fli6bZbJ1Oeez58Xn5jeoGnZnyFHXOySWXXJJx48blqKOOyl133ZULLrggEydOzOabb54HHnig0uNRQf/9B0yStG7dOt9cu2veeuvf/6Nr1Kio/6SBz/FZr+u1/ut1fdnwi7PFVlvXCROgLPv2XC9b91g9R597Z4Pv+7vbd8+yLZvnqjv/3uD7pjxFHTn59a9/nfb/9cuqV69e6dKlS37xi19k++23r9BklGjy5Ml5/vnn8u1ttqv0KEAD+XDy5Lzw/HPZ+tufvK7fevONvD5+XHbuvUtOH3xKrrvmqrz3XnW6rPnNHHHMcdl3vwMqPDGwUttWOeuIXhn4m7/krXc//MztlmneNK/ddnxWatsqE6qn5I6//jNDrnww70+Z/rn7P3CXDTN56ozc+uCYhh6dAhUVJ/8dJskn76J169Ytb7zxRgUmomQnHHNEPpo2LcedeFKlRwEayInHfvK6PubEnydJ/vX2W0mSG0b+Lh07rpozzrkgy7Vpk99ddWUO/+mPMmvWrBxw0I8rOTIs9S44dpe8/EZ1Lrv96c/c5n/HvpOTxv45o197J0mydY/OOWKvLbLtRl/Ptw6+LNOmz5rv/dZabcVsse5qufwPT89zfgpLpqLiZH4mT56cZ5999guPmkycODHvvvtunWVjx45dmKNRQcOGnJqbfj8yvzrngnmu6gMsnn45ZFBu/v31OePs82tf13Pnzk2SzJwxIzfc+sd0Wm31JMm22++YHbbeLGefMUycQAXtuU3X9Nnym9n8R5d+7nYX3fREndsPPPNqnn/5X7l+6L754a4bzbP+UwfusmGS5Oo/PdswA1O84j+gf9hhh2XatGk5+eSTP3e74cOHp3v37nV+9txzz0UzJIvUr34xJGf/6hc5ZfDQHPyzwyo9DtAAzvzF0Jxz5i9y8qCh+fF/vK6XX6FdkmTNtb5ZGyZJUlVVle133Clvv/Vm3p04cZHPCyStlmmW847eJZfc+lT+VT0lbVq3SJvWLdKsSeMkSZvWLdKyRdPPvP8fHvlnpn40M5uus+p81zdp3Cjf23n9PP/yv/LsS28vlMdAeYo+cjJw4MBcd911ueiii77wal2HHnpo9tprrzrLxo4dK1CWML/6xZCcMWxIfn7yqTnuBB/ngiXBmb8YmjN/MSQnDjg1x5zw8zrr1vj6N9KyZcv53q+mpiaJC2FApbRr0zId2i2bo/fdKkfvu9U86yfcdVLuePTF7H3yDZ+5j6qqqsydWzPfdX22XCsrr9A6Z1zryptLk2Lj5LTTTsvpp5+eYcOG5fDDD//C7du3bz/fc1ZYcpx1xuk5Y9iQHP8/A2ovFwws3s4+Y1jO/MWQHHfigJw4YOA865s0aZJeu+yeO26/Ja+PH1f7hao1NTV54L57s8bXv5F2K664iKcGkuSd96ZmpyOvmmf58ft9K1v36Jw9ThiR6smf/V1E/bbtllbLNPvMywv/YJcNM33mx7nhzy802MyUr8g4Oe200zJ48OAMHjw4AwYMqPQ4FODiC87NL4YOzg49d85Ovfrk6b89WWf9Jv//EqOT3n03j/31kSTJmNGjkiT3/fmerLjiSllxxRWz1dbbLNrBgc/06wvPyxmnf/K67tmrd575r9f1p5cOPmng4Nx/3z3Ze89dc+KAgVl2ueUy4urfZtT/vpArr72+EqMDSWbOmp1H/zFunuXf790jc+bMrV232sptcvWp381N94/KK29Vp6bmkxPiD99r84x+9Z1c9ad5LxG8Srtls9OmXXLzg6PzwdQZC/mRUJLi4mTo0KEZPHhwTjnllAwaNKjS41CIe+7+U5Lk/vvuzf333TvP+venzU6S/PPF0Tlw/33qrDv+6E+OvG219bfzp3t8Xw6U4t67Pv91PWnqJ1fmWePr38if7n0wQwadnGOPPCSzP/443ddbPyNuvC07995lkc4MLLgPp83MxPen5sh9tkj75VulcaNGef2dDzL8lqdy5u8eyUcz5r0K1/69e6RJk8bzDReWbFU1n35otwDnnHNOjj/++PTq1Wu+YbL55gv2BVyjR49O9+7d8/jTz6drt3UaakygwuaU878toAGt2ntopUcAGtDcaRMz69lLM2rUqKyzzpf7W7yoIyd33HFHkuSee+7JPffcM8/6gjoKAABoYEXFyUMPPVTpEQAAgApx/UUAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAitCk0gMsTDNnzkySvPrK2ApPAjSkuTU1lR4BWAjmTptY6RGABjR3+ntJ/v03+ZexRMfJG2+8kSTZf9/vVHgSAABYOr3xxhvZcMMNv9S2VTU1S+5bkB988EEefvjhdOrUKc2bN6/0OCxEY8eOzZ577pnbb789Xbp0qfQ4QAPx2oYlj9f10mPmzJl54403ss0226Rt27Zf6j5L9JGTtm3bZo899qj0GCxCXbp0yTrrrFPpMYAG5rUNSx6v66XDlz1i8iknxAMAAEUQJwAAQBHECQAAUARxwhJhpZVWyqBBg7LSSitVehSgAXltw5LH65rPs0RfrQsAAFh8OHICAAAUQZwAAABFECcAAEARxAkAAFAEccJiberUqTn66KPTsWPHtGjRIj169MgNN9xQ6bGAr2DKlCk58cQTs9NOO2WllVZKVVVVBg8eXOmxgK/ggQceyA9/+MOsvfbaadWqVb72ta9ljz32yN///vdKj0ZhxAmLtX79+uWaa67JoEGDcvfdd2eTTTZJ//79M3LkyEqPBtRTdXV1LrvsssycOTN77rlnpccBGsAll1yScePG5aijjspdd92VCy64IBMnTszmm2+eBx54oNLjURCXEmaxddddd2WXXXbJyJEj079//9rlO+20U0aPHp3XX389jRs3ruCEQH18+mupqqoqkyZNqv1OBEdPYPE1ceLEtG/fvs6yqVOnpkuXLunevXv+8pe/VGgySuPICYut2267La1bt85ee+1VZ/lBBx2Ut99+O0899VSFJgO+iqqqqlRVVVV6DKAB/XeYJEnr1q3TrVu3vPHGGxWYiFKJExZbo0aNSteuXdOkSZM6y9dbb73a9QBAmSZPnpxnn30266yzTqVHoSDihMVWdXV1VlhhhXmWf7qsurp6UY8EAHxJhx12WKZNm5aTTz650qNQkCZfvAmU6/M++uFjIQBQpoEDB+a6667LRRddlI022qjS41AQR05YbLVr126+R0fee++9JJnvURUAoLJOO+20nH766Rk2bFgOP/zwSo9DYcQJi6111103L774YmbPnl1n+f/+7/8mSbp3716JsQCAz3Daaadl8ODBGTx4cAYMGFDpcSiQOGGx1bdv30ydOjW33HJLneXXXHNNOnbsmM0226xCkwEA/23o0KEZPHhwTjnllAwaNKjS41Ao55yw2Ordu3d69uyZQw45JB9++GG6dOmS66+/Pvfcc09GjBjhO05gMXb33Xdn2rRpmTJlSpJkzJgxufnmm5Mkffr0ScuWLSs5HrCAzjnnnJx66qnp1atXdtlllzz55JN11m+++eYVmozS+BJGFmtTp07NySefnBtvvDHvvfde1l577Zx00knZd999Kz0a8BV07tw548ePn++61157LZ07d160AwFfybbbbpuHH374M9f7c5RPiRMAAKAIzjkBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAPjSxo0bl6qqqlx99dW1ywYPHpyqqqoF3tfIkSNz/vnnN9xw/6Fz58458MADv3C7qqqqDB48eIH3/+nzcPbZZy/4cF+wz/98bgGWNuIEgK/kxz/+cZ544okFvt/CjBMAFk9NKj0AAIvG9OnTs8wyyzT4flddddWsuuqqDb5fAJY+jpwALCY+/fjUc889l379+mW55ZZLmzZtsv/+++fdd9+ts23nzp2z66675tZbb80GG2yQFi1a5LTTTkuSTJgwIT/96U+z6qqrplmzZlljjTVy2mmnZfbs2XX28fbbb2fvvffOsssumzZt2mSfffbJhAkTPnOu/zZy5MhsscUWad26dVq3bp0ePXrkyiuvTJJsu+22ufPOOzN+/PhUVVXV/nxq1qxZOf3007P22munefPmWWmllXLQQQfN8zg//vjjnHjiienQoUNatmyZb33rW/nb3/5Wvyc4ybvvvptDDz003bp1S+vWrdO+fftsv/32efTRR+e7/dy5czNs2LCsttpqadGiRTbeeOPcf//982z38ssv53vf+17at2+f5s2bp2vXrvn1r39d7zkBllSOnAAsZvr27Zu99947P/vZzzJ69OgMHDgwY8aMyVNPPZWmTZvWbvfss8/mxRdfzCmnnJI11lgjrVq1yoQJE7LpppumUaNGOfXUU/ONb3wjTzzxRE4//fSMGzcuV111VZJPjrLsuOOOefvtt/PLX/4ya621Vu68887ss88+X2rGU089NUOHDk2/fv1y3HHHpU2bNhk1alTGjx+fJBk+fHgOPvjgvPLKK7ntttvq3Hfu3LnZY4898uijj+bEE0/MlltumfHjx2fQoEHZdttt88wzz9QeAfrJT36Sa6+9Nscff3x69uyZUaNGpV+/fpkyZUq9ntv33nsvSTJo0KB06NAhU6dOzW233ZZtt902999/f7bddts621988cVZffXVc/7552fu3Lk588wz07t37zz88MPZYostkiRjxozJlltumdVWWy3nnHNOOnTokHvvvTdHHnlkJk2alEGDBtVrVoAlUg0Ai4VBgwbVJKk55phj6iy/7rrrapLUjBgxonbZ6quvXtO4ceOal156qc62P/3pT2tat25dM378+DrLzz777JokNaNHj66pqampueSSS2qS1PzhD3+os91PfvKTmiQ1V1111TxzferVV1+tady4cc1+++33uY9nl112qVl99dXnWX799dfXJKm55ZZb6ix/+umna5LUDB8+vKampqbmxRdf/Nzn4wc/+MHn/vs1NTU1SWoGDRr0metnz55d8/HHH9fssMMONX379q1d/tprr9UkqenYsWPN9OnTa5d/+OGHNSussELNjjvuWLts5513rll11VVrJk+eXGffhx9+eE2LFi1q3nvvvTr7/M/nFmBp42NdAIuZ/fbbr87tvffeO02aNMmDDz5YZ/l6662XtdZaq86yP/3pT9luu+3SsWPHzJ49u/and+/eSZKHH344SfLggw9m2WWXze67717n/t/73ve+cL777rsvc+bMyWGHHbbAj+3TGdu2bZvddtutzow9evRIhw4d8tBDD9XOmHz281Ffl156aTbccMO0aNEiTZo0SdOmTXP//ffnxRdfnGfbfv36pUWLFrW3l1122ey222555JFHMmfOnMyYMSP3339/+vbtm5YtW9Z5PH369MmMGTPy5JNP1ntWgCWNOAFYzHTo0KHO7SZNmqRdu3aprq6us3yVVVaZ577vvPNO7rjjjjRt2rTOzzrrrJMkmTRpUpKkuro6K6+88hf+2/Pz6Xkh9T1J/p133skHH3yQZs2azTPnhAkT6sw4v5k+fT7q49xzz80hhxySzTbbLLfcckuefPLJPP300+nVq1emT58+z/bzez46dOiQWbNmZerUqamurs7s2bNz0UUXzfNY+vTpk+TfzzkAzjkBWOxMmDAhX/va12pvz549O9XV1fP8QT6/k9RXXHHFrLfeehk2bNh8992xY8ckSbt27eZ7Yvn8Toj/byuttFKS5M0330ynTp2+cPv5zdiuXbvcc889812/7LLL1s746Uzzez7qY8SIEdl2221zySWX1Fn+WeewzO/5mDBhQpo1a5bWrVunadOmady4cb7//e9/5pGkNdZYo16zAiyJxAnAYua6667LRhttVHv7xhtvzOzZs+c5WXt+dt1119x11135xje+keWXX/4zt9tuu+1y44035o9//GOdj3aNHDnyC/+NnXbaKY0bN84ll1xSe1L4/DRv3ny+RyN23XXX3HDDDZkzZ04222yzz7z/p4/3s56P+qiqqkrz5s3rLHvhhRfyxBNPzDe0br311px11lm1H+2aMmVK7rjjjmy99dZp3LhxWrZsme222y7PPfdc1ltvvTRr1qxecwEsLcQJwGLm1ltvTZMmTdKzZ8/aq3Wtv/762Xvvvb/wvkOGDMl9992XLbfcMkceeWS++c1vZsaMGRk3blzuuuuuXHrppVl11VVzwAEH5LzzzssBBxyQYcOGZc0118xdd92Ve++99wv/jc6dO2fAgAEZOnRopk+fnv79+6dNmzYZM2ZMJk2aVHtJ43XXXTe33nprLrnkkmy00UZp1KhRNt544+y777657rrr0qdPnxx11FHZdNNN07Rp07z55pt58MEHs8cee6Rv377p2rVr9t9//5x//vlp2rRpdtxxx4waNSpnn312lltuuXo9t7vuumuGDh2aQYMGZZtttslLL72UIUOGZI011phv8DRu3Dg9e/bMsccem7lz5+ZXv/pVPvzww9rHmCQXXHBBvvWtb2XrrbfOIYccks6dO2fKlCkZO3Zs7rjjjjzwwAP1mhVgSSROABYzt956awYPHpxLLrkkVVVV2W233XL++ed/qXflV1lllTzzzDMZOnRozjrrrLz55ptZdtlls8Yaa6RXr161R1NatmyZBx54IEcddVR+/vOfp6qqKjvttFNuuOGGbLnlll/47wwZMiRrrrlmLrroouy3335p0qRJ1lxzzRx55JG12xx11FEZPXp0BgwYkMmTJ6empiY1NTVp3Lhx/vjHP+aCCy7I7373u/zyl79MkyZNsuqqq2abbbbJuuuuW7uPK6+8MiuvvHKuvvrqXHjhhenRo0duueWW7LvvvvV4ZpOTTz45H330Ua688sqceeaZ6datWy699NLcdttttSfi/6fDDz88M2bMyJFHHpmJEydmnXXWyZ133pmtttqqdptu3brl2WefzdChQ3PKKadk4sSJadu2bdZcc83a804A+ERVTU1NTaWHAOCLDR48OKeddlrefffdrLjiipUeBwAanKt1AQAARRAnAABAEXysCwAAKIIjJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFCE/wevrySiP+pIlQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x960 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Modelo '{nome_estimador}', transformer '{nome_transformer}':\")\n",
    "plot_confusion_matrix(conf_mat=cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente o modelo tem uma leve dificuldade em prever *tweets* de tom neutro. No entanto, mesmo nesse caso, **o *recall* para esta classe √© superior a 90%**, corroborando o desempenho excelente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outros modelos que performaram muito bem foram **o estimador de *Random Forest* com *transformer* *Word2Vec***...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'random_forest', transformer 'word2vec':\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.84       494\n",
      "           1       0.78      0.82      0.80       502\n",
      "           2       0.86      0.84      0.85       504\n",
      "\n",
      "    accuracy                           0.83      1500\n",
      "   macro avg       0.83      0.83      0.83      1500\n",
      "weighted avg       0.83      0.83      0.83      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_pipeline = 'random_forest.word2vec'\n",
    "nome_estimador, nome_transformer = nome_pipeline.split('.')\n",
    "est = pipelines[nome_pipeline]\n",
    "\n",
    "y_pred = est.predict(X_test)\n",
    "\n",
    "print(f\"Modelo '{nome_estimador}', transformer '{nome_transformer}':\")\n",
    "print(classification_report(\n",
    "    y_true = y_test,\n",
    "    y_pred = y_pred\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'random_forest', transformer 'word2vec':\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x960 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Modelo '{nome_estimador}', transformer '{nome_transformer}':\")\n",
    "plot_confusion_matrix(conf_mat=cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... e o estimador ***XGBoost*, tamb√©m com *transformer* *Word2Vec***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'xgboost', transformer 'word2vec':\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       494\n",
      "           1       0.78      0.82      0.80       502\n",
      "           2       0.86      0.84      0.85       504\n",
      "\n",
      "    accuracy                           0.82      1500\n",
      "   macro avg       0.82      0.82      0.82      1500\n",
      "weighted avg       0.82      0.82      0.82      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nome_pipeline = 'xgboost.word2vec'\n",
    "nome_estimador, nome_transformer = nome_pipeline.split('.')\n",
    "est = pipelines[nome_pipeline]\n",
    "\n",
    "y_pred = est.predict(X_test)\n",
    "\n",
    "print(f\"Modelo '{nome_estimador}', transformer '{nome_transformer}':\")\n",
    "print(classification_report(\n",
    "    y_true = y_test,\n",
    "    y_pred = y_pred\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'xgboost', transformer 'word2vec':\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAycAAAMrCAYAAABTa+3SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAABJ0AAASdAHeZh94AABCZklEQVR4nO3deZhWdf3/8dewb4qyiQiIiiaIO+4abqAgqVjuWmqluZuZGYpskuaSa2Aaroj7UiZpqYm2aJa2oOZXVHALWQQUBBSY3x/+nJpAhRGYj/B4XBfX9Z3POfeZ9z3fi5wn5z7nVFRWVlYGAACgltWp7QEAAAAScQIAABRCnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQhHq1PcDyNGPGjIwdOzYdOnRIw4YNa3scAABYZcybNy+vv/56evTokTXWWGOJXrNSx8nYsWOz//771/YYAACwyrrvvvuy3377LdG+K3WcdOjQIUlSb+MDU6dxi1qeBlhWHvzpd2p7BGA5aN6kfm2PACxDL48fn4O+tn/V7+RLYqWOk48/ylWncYvUadqmlqcBlpUvdela2yMAy0GLZg1qewRgOViayytcEA8AABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnFO+ovltlzhNDMuWhsxfZtsVGa+eBS7+RKQ+dnX+P+WFuO++QdFp7zWr7dO7QMuefsFf+8PPv5N9jfpg3Hzgrjw7/Vvrt2nVFvQXgU/z5T3/IkQfum66d1soGazfPTlt3zaUX/ahq+8ifXZW+PXdJtw3aZb21Vss23Trn+GOOyIsvPF+LUwOf5LHfPZrjvnVMNu+2cVo2b5r1110nBx6wX57561+r7VdZWZmfXnlFNu+2cZo3bZj1OqydU048PtOnT6+lySlBcXEya9asnHbaaWnXrl0aNWqULbbYIrfddlttj0UtaddqtZx/wl55a8q7i2zbqGOrPHTF0WlQr26OGHhHvnPBfencoWUe+ek302qNJlX77bnNBtl7h41y39jnc/i5d+ToIXdn/BvTMnroIfnhUbuuwHcD/K9777wtX+27Z1ZbvXkuGzEyN93xi5x46hlJZWXVPtPfeSe777lXLr5iREbf80DO+OGAjPvn39K3584Z/9KLtTg9sDjX/GxEJk6ckBNPOjX33T8mF//k8kyePDk9dt4+j/3u0ar9zjrzjJx5xnfT9yv75Z5f/Crf+/5Zuf220em7d898+OGHtfgOqE0VlZX/9V+AAvTq1StPP/10Lrjggmy00UYZPXp0fv7zn+eWW27JYYcdtlTHeu6559KtW7c02PK41GnaZjlNzPJ01wWHp7KyMtPfm5N+Pbqm9V7DqraNGnxQvrzVetnk4Mvy3vvzkiQd12qef956aq6840855+rfJklaNm+SaTPfX+TYd//48PTYcr202+f8fPDhghXzhlgmXr7/nNoegWXg32+9mS9vu2m+dvDhOf+SK5fqtS+9+EJ23X6LnPb9/vl+/4HLaUJWtBbNGtT2CCwDkydPTps21X/vmjVrVrpt3DldN+mWMQ89nDfffDNf2mDdHPudE/KTy66o2u/2227NUUcelp+OuCbHfOvbK3p0lrHnn3suW2/RLePGjcsmm2yyRK8p6szJmDFj8tvf/jbDhw/Pcccdl9122y3XXnttevbsme9///tZsMAvkKuSQ3ptll22WDen/eRXi2yrW7dOeu+4Ue577PmqMEmS196embHPTsi+X+5Stba4MEmSv7zwZpo2bpAWqzde9sMDn+nWm6/P+7Nnf3SmZCm1bNU6SVKvXr1lPRbwOf1vmCRJs2bNsnGXrnnjjdeTJH9+6sksWLAge/fuU22/Pvv0TZLcd+/dy39QilRUnNx7771p1qxZDjzwwGrrRx99dN5666089dRTtTQZK1rrNZrmopN7Z8DVv82bi/lI1/rt1kyTRg0y7uVJi2wb9/KkbLBOizRs8Om/tPTYcr1Mnj4rk6fPXmZzA0vuyT8+kTXWbJHxL72Ynrtsk46tmmSzDdvnB989Me+9u+jf+wULFmTevHkZ/3//yhmnfCetWrfJQYd9vRYmB5bWzJkz87dnn0mXrh/96/kHH3yQJGnYsGG1/erXr5+Kior885//WOEzUoai4mTcuHHp0qXLIv8Sttlmm1VtZ9Vw+ff65qXXp+Wa+55e7PaWzT+6pmT6e3MW2fbOu3NSp06drLlao088/lF9t0qPrdbLj28cm4ULi/pkI6wyJv37rcyd836OO/qw7NvvwNx2369z/MnfzV2335IjD9ov//up4w3XWTPrt109PbbbPC/9379y1/2/yTrtO9TS9MDSOO3kEzN79uz84KyPbm7TpctHN6X50x//UG2/J//0x1RWVuadadNW+IyUoajz4dOmTcv666+/yHqLFi2qtn+SyZMnZ8qUKdXWxo8fv2wHZIXYv0fX9NnxS9n+myM+c99Pu2Lqk7b12m7DXPbdvrnnd+My/G5n46C2LFy4MHPnzs0PzzwnJ333+0mSHXfukfoNGmTgD8/IE2MfzZd33aNq/188NDYffPBBJr76Sq4dcUUO3Hev3H7fg/lSF3feg5INHjggt916S35y2ZXZauutkySbbb55dt7ly7n0kouy4UZfyh579swLzz+fk0/8TurWrZs6dYr693NWoOL+P19RUVGjbcOHD0+3bt2q/dl///2Xw4QsT00bN8il390nI+5+Kv+e+l6aN2uU5s0apUG9ukmS5s0apUmj+lXXkSzuepEWqzfOwoULM2PW3EW27blt59w27JA88peXc9QQn2eF2rRmi5ZJkl336Fltfbc990qSjPv7s9XWN918y2y9zXY54KBDc+cvf5PKyspcMHTAihkWqJFhQwfngh+dl8FDh+X4E0+qtu2W2+7MDjvulCMOPShrt14ze/fcLfvtf0A233yLtFtnnVqamNpW1JmTli1bLvbsyDvvvJPkP2dQFueEE05Y5FqV8ePHC5QvmJbNm6Rty9Vy2qE75bRDd1pk+6Rf98/9T7yQQwfcnvfnfpBNNlhrkX02WX+tvPzmO5n3wfxq63tu2zl3/OjQPPG3CTn0nNvy4Xw3WIDa1KVrtzzz9KJnLz/+ONen/ctps9VWS+cNv5RXXn5puc0HfD7Dhg7OeUMG5ZxzB+XMs/ovsr1Nmza57/4xmTx5ct6eNCkd1103jRs3zjVXD0+/A7624gemCEXFyaabbppbb7018+fPr3bdyT//+c8kSbdu3T7xtW3atFns3SH4Ynn7nVnpdfJ1i6yfccQu2WWLTtnvjJszbeb7WbBgYcb84cXs9+WuOXv4bzJrzkcX1nVo0zw9tlwvV97xp2qv32ObDXLHjw7NH//xWg7qf6tbB0MB9tm3X265cWQe/e1D6bbZFlXrj/72wSTJVt23+8TXvjNtav71/Lh0326H5T0mUAPnDxua84YMyln9z8nZAz79dt///TvcT6+8IrNnz853TjjpU1/DyquoOOnXr1+uvfba3H333Tn44IOr1m+88ca0a9cu2233yf+hYuUw74P5eeJvExZZP7LPllmwYGG1bUOv+11+f+1GuefCI3LxqCfSqEG9DPjm7pk28/1cfvt/LrDbcdOOueNHh+btabNy4c2PZ/PObasd+4UJU6rdjhhYMXrs3jM9994nl100LAsrF2ar7tvmH88+k0svPC977tUn2+6wU96dOTOHHtAn+3/t4Ky3fuc0atw4r4x/KSN/dlXmfTAvp//AM2+gNJddekmGDDo3vfbaO3v33idPPflkte3bbb99kuS6n1+bJFl/gw0yY8aM/ObBX+eG60dm8Hk/ypZbbbXC56YMRcVJ796907Nnzxx//PF5991307lz59x666158MEHM2rUqNStW7e2R6Qg//fa1Ox18nU57/heGT304MxfsDBjn3klB/V/KFNn/OfZJrt13yBNGjVIp3YN8tAVRy9ynF4nX7fYIAKWvxHX3ZJLf3xebrlhZC798XlZq227fOv4U6qio2GjRunabbPccuPIvPXmG5k3d25at2mbHXb+cq698fZstHGXz/gOwIo25lf3J0l+89CD+c1DDy6yfc6HH310s7KyMlddeVlemzgxderUyeZbbJnb77o3X9l3vxU6L2Up7gnxs2bNytlnn5077rgj77zzTjbeeOP88Ic/zCGHHLLUx/KEeFg5eUI8rJw8IR5WLjV5QnxRZ06Sj54gevnll+fyyy+v7VEAAIAVqLhbCQMAAKsmcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARahX2wOsCA9f/Z1s3GWT2h4DWEY69jy7tkcAloMpYy+o7RGAZWjBwoVL/RpnTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAj1lmbnIUOGLPG+FRUVGTBgwFIPBAAArJqWKk4GDRq0xPuKEwAAYGksVZwsXLhwec0BAACs4lxzAgAAFGGpzpwszr/+9a+MHTs2U6dOzTe/+c20bds2b731VtZcc800btx4WcwIAACsAmocJwsWLMixxx6bG264IZWVlamoqEjv3r3Ttm3bHHfccdlyyy2X6gJ6AABg1Vbjj3UNGzYso0ePzkUXXZRx48alsrKyalvv3r3z4IMPLpMBAQCAVUONz5zccMMNGTBgQE4//fQsWLCg2rb11lsvr7766uceDgAAWHXU+MzJm2++mR122GGx2xo1apT33nuvxkMBAACrnhrHSZs2bfLKK68sdtuLL76Y9u3b13goAABg1VPjOOnTp0+GDRuWN998s2qtoqIiM2fOzBVXXJGvfOUry2RAAABg1VDjOBkyZEjmz5+frl275qtf/WoqKirSv3//dOvWLXPnzvV0eAAAYKnUOE7WWmutPP300zn00EPz17/+NXXr1s3f//739O7dO3/84x/TokWLZTknAACwkvtcD2Fca621cvXVVy+rWQAAgFXY535CfJK89dZbmTZtWlq2bJl27doti0MCAACrmBp/rCtJ7rnnnnzpS19Khw4dssUWW6RDhw7ZaKONctdddy2r+QAAgFVEjePk9ttvz9e+9rXUrVs35557boYPH54BAwakbt26Ofjgg3P77bcvyzkBAICVXI0/1jVkyJD07t07999/f+rU+U/jnHvuudlnn30yZMiQHHzwwctkSAAAYOVX4zMnL7/8ck444YRqYZIkderUyQknnJCXX375cw8HAACsOmocJ+uuu27ef//9xW57//3306FDhxoPBQAArHpqHCff+973MmTIkEydOrXa+uTJk3PeeefljDPO+NzDAQAAq46luubklFNOqfb1u+++m06dOmWPPfZI27ZtM2nSpDzyyCNp1apVnn/++WU6KAAAsHJbqji56qqrFrt+//33V/v6tddey1VXXZXLL7+85pMBAACrlKWKk4ULFy6vOQAAgFXc53oIIwAAwLIiTgAAgCJ8rjgZNWpUunfvnqZNm6Zu3bqL/AEAAFhSNY6TX/7ylzn66KOz5ZZbZs6cOTn66KNz6KGHpmnTptlwww1z7rnnLss5AQCAlVyN4+SCCy7I6aefnquvvjpJcsIJJ2TUqFH5v//7vyxYsMBDGAEAgKVS4zh58cUXs+eee6aioiJJMn/+/CRJ27Ztc8455+QnP/nJspkQAABYJdQ4ThYsWJAGDRqkTp06adq0aSZNmlS1rWPHjnnllVeWyYCQJH94YmzarN5gsX/+8uenFvuaysrK7Lv37mmzeoOc9b1TV/DEwKc5at9tM+fJCzPl0aHV1nfcvFOG9/9a/nDDKZnx+I8y58kL03HtNT/xOMcfuGP+dtsZmfH4j/LCPWel/zf3TL267vUCtekff/9bvrp/33Tp3Cmt12iajmu3yu49dspto0dV26+ysjLXj7w2u+ywTdq1XiMd27XO3nvulgd//UAtTU4Jluo5J/9tvfXWy1tvvZUk2XzzzXPrrbdm3333TZLcddddWXvttZfNhPBfzh44NDvtsmu1tY27brLYfa+7ZkRefeXlFTAVsDTatV4955+8T96aPDOrN2tUbduu3Ttn92065+8vvpX3Zs9Lj603+MTjnHnU7hl4bK9cfNNjefjP/5fuXTpk4HF7pV3r5jnpgruX99sAPsHMGTPSvn2HHHjQIWnXbp3Mfn927rh1dL59zDfy2sSJOfOHZydJhg0ZlB+ff16++e3jMnjojzJ33tz8bPhVObDfvhl1253Zb/8DaveNUCtqHCd77LFHHn744Rx66KE59dRTc/DBB+fpp59OgwYN8uKLL+aCCy6o0XHfe++9DB06NH/729/y7LPPZurUqRk4cGAGDRpU01FZiay/Qed033a7z9zvtYkTct7gc3LVz67L0YcftAImA5bUFT84IL//26uZ/u776bfbptW2nX/dI/nRyIeTJKcd9uVPjJMWqzfJWUftket+8ecMvPrBJMkTz7ySevXqZNBxe+Wq257IvyZMXr5vBFisXXrsml167FptrXefvpkwcUKuH3ltVZzcfNP12WHHnXPZlcOr9tt9j57pvG67jB51kzhZRdX43PewYcNy6aWXJkkOPPDA3HXXXdl8883TtWvXjBw5Mt///vdrdNxp06blmmuuybx587L//vvXdDxWcd875YT02G2P7POV/Wt7FOC/HLL3ltlly/Vz2oX3LnZ7ZWXlEh2n1w5fSuNG9XPzr/5Sbf3mX/0lderUyVd6LP6MKlB7WrZsmXr1/vPv4vXr1c/qzVevtk+jRo3SsFGjNGrU6H9fziqixmdOGjZsmIYNG1Z9fcABB+SAAz5/4a677rqZPn16KioqMnXq1Pz85z//3Mdk5fGD752aY48+Io2bNEn3bbbP6T/on+132KnaPqNuvC7PPvN0fv/nv9fSlMDitF6zaS46bd8MGP7rvDll5uc6Vtf110qSjHv539XWJ017L1Omz8om67f9XMcHPr+FCxdm4cKFmT59eu6756488tvf5JJLr6jafvxJp+Tss76fG68fmX33PyDz5s7NZZdenHdnzsx3Tji5FienNtU4TpaXj+/+Bf9t9dVXz7HHn5wdd/lyWrRomVdfeTk/vfyS9OuzZ2658xfZfc9eSZJ/v/VmBp3zg5w75Py0XbtdLU8N/LfLv98vL702Jdfc/afPfawWzZtm7rwP8/7cDxfZNv3dOWnRvMnn/h7A5/PdU07MdT+/JknSoEGDXPSTy3LMt4+r2n7iyaemcaNG+d5pJ+ek449NkqzZokXuuPsX2WHHnRZ7TFZ+SxUnxxxzzBLvW1FRkZEjRy71QDU1efLkTJkypdra+PHjV9j3Z/nadPMts+nmW1Z9vf2OO6dP3/3SY4etMuTcH1bFyfdPOzGbdNssRx71zdoaFViM/Xfrlj47d832X79smR3z0z4BtoSfDgOWozPO/GG+cfQ3M2XK5Pz6gV/le6edktmz38+p3/1ekuTmG6/PmWd8N8cef2J69do7H3z4QW4ddXMOObBfbrn9ruzZc69afgfUhqWKk0cffXSJz2ys6DMgw4cPz+DBg1fo96R2NV9jjfTcu09uHHlN5syZk4cfGpNHH/5N7n/osbw7s/pHRj788IPMnDEjTZo2Tf369WtpYlg1NW3cIJee0S8j7vxD/j313TT//3foalCvbpKkebNG+XD+gsWeBfkk78ycncaN6qdxw/qZM6/669ZcvXGe/df7y+4NADXSoWPHdOjYMUmy1959kiSDBvTPYUd8PfXq1cv3Tjs53zj6m/nRBRdVvabXXr3Tu+fuOe2kEzLuRXfcXBUtVZxMmDBhOY3x+Z1wwgk58MADq62NHz/eRfUruY8vnq2oqMgLzz+X+fPnp/ceOy+y3803jMzNN4zMDaPvTJ+++63oMWGV1nKNpmnbcrWcdniPnHZ4j0W2T3p4SO4fOy4H/eCmJT7mcy9/9Gytbp3b5unnXq9aX6tFs7Res1mee2XSJ70UqCVbd98mI6/9WSa8+koqKyszZ86cbLV190X223LrrfP7J8Zm1qxZadasWS1MSm0q7pqTmmrTpk3atGlT22OwAs2YPj2/fXBMum22eRo1apRDDv96dtpl0V98+u3TM7377ptjjz/5E5+JAiw/b097L71OuHqR9TOO3C27bLl+9jt9ZKbNmL1Ux/zNky9mztwPc8Q+3avFyZH7dM/ChQtz/9jnPvfcwLL1xNjHUqdOnXRab/3MnTMnSfL0n5/K4Ud+o2qfysrKPP3UU1lzzTXTtGnT2hqVWrTSxAkrt+8cc2TW6dAhW2y5dVq0bJVXXh6fEVdemimT384VIz66o1vHdTul47qdFvv6tddeZ7HhAix/8z6YnyeeeWWR9SP36Z4FCxdW29ZqjabZZcv1kySbbPDRHbf22uFLmTp9dqbMmJ3fP/vRvtPfnZMLbngkA4/tlenvvp+Hn3op3bu0z9nf6pnrf/m0Z5xALTr5hOOy2uqrp3v3bdKmzVqZNm1q7r3nrtx95x059fQz0rp16yTJvvv3y/Ujr03Dhg3Ta6/emffBvIwedVOe/NMfMmDgEDdJWkWJE74QunbbNPfdc2duvO7azJ41K2uu2SLb7rBjfnrNDdlyMaeEgS+mLuuvldHnH1lt7YozP7pN/ePPvJy9TvhZ1fqFNzyaWe/Py3Ff3TGnHdYjb097Lxff/Fh+fP0jK3Jk4H9su932GXXTjRk96qbMnDEjzZo1S7dNN8+1192YQw47omq/kTeMys9G/DS3jR6Vm2+8PvXq10/nDTfKz6+/KQcdclgtvgNqU0Xlkj7xagX69a9/ndmzZ+e9997LMccckwMPPDAHHfTRU7779OmTJk2W7BaRzz33XLp165bHn3o2G3fxcR5YWXTseXZtjwAsB1PGXlDbIwDL0AvPP5dtt9os48aNyyabLNnv4kWeOTn++OMzceLEqq/vvPPO3HnnnUmSV199NZ06daqlyQAAgOWlyDgp+a5gAADA8vG542TmzJl58sknM3Xq1PTp0ydrrrnmspgLAABYxdT5PC8eOnRo2rVrl969e+frX/96Xn311STJHnvskQsu8LlRAABgydU4Tj5+Ivs3v/nNPPDAA/nv6+r79u2bBx54YJkMCAAArBpq/LGuq666KqeffnouvPDCLFiwoNq2DTfcMC+99NLnHg4AAFh11PjMySuvvJK99tprsdtWW221zJgxo6aHBgAAVkE1jpPmzZvn7bffXuy2CRMmpE2bNjUeCgAAWPXUOE722GOPXHjhhZk9e3bVWkVFRebPn58RI0Z84lkVAACAxanxNSdDhgzJNttsk65du6Zfv36pqKjIVVddlWeffTavvfZa7rjjjmU5JwAAsJKr8ZmTzp075w9/+EO6dOmS4cOHp7KyMjfddFNatWqVJ554Ih07dlyWcwIAACu5z/UQxq5du+bBBx/MvHnzMm3atKy55ppp3LjxspoNAABYhXzuJ8QnScOGDdOuXbtlcSgAAGAV9bmuOfk0FRUVGTBgQE0PDwAArGJqHCeDBg361O3iBAAAWBo1viB+4cKFi/yZOnVqfv7zn6dbt26ZMGHCMhwTAABY2dU4ThanRYsWOeaYY3LYYYfllFNOWZaHBgAAVnLLNE4+tu222+aRRx5ZHocGAABWUsslTv7+97+nWbNmy+PQAADASqrGF8TfdNNNi6zNmzcv//jHP3LdddfliCOO+FyDAQAAq5Yax8lRRx212PVGjRrliCOOyMUXX1zTQwMAAKugGsfJq6++ushao0aNstZaa32ugQAAgFVTjeJk7ty5+dnPfpavfvWr2XrrrZf1TAAAwCqoRhfEN2rUKJdeemlmz569rOcBAABWUTW+W1eXLl0W+9EuAACAmqhxnAwYMCDnnXdeXn755WU5DwAAsIqq8QXx119/fd5///106dIlm222WdZee+1UVFRUba+oqMgvfvGLZTIkAACw8qtxnPzjH/9IgwYNss4662TatGmZNm3aspwLAABYxdQ4TiZMmLAMxwAAAFZ1Nb7m5PHHH8+sWbMWu2327Nl5/PHHazwUAACw6qlxnOy22255/vnnF7vtX//6V3bbbbcaDwUAAKx6ahwnlZWVn7jtww8/TJ06NT40AACwClqqa07efffdzJgxo+rrSZMm5bXXXqu2z5w5c3LjjTembdu2y2RAAABg1bBUcXLppZdmyJAhST66VXC/fv0Wu19lZWX69+//+acDAABWGUsVJ7169UqzZs1SWVmZM888MyeffHI6duxYbZ+GDRtm0003TY8ePZbpoAAAwMptqeJkhx12yA477JDkoztyffvb3067du2Wy2AAAMCqpcbPORk4cOCynAMAAFjFuaUWAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHq1fYAK0KTBvXSrNEq8VZhlfDGwz+q7RGA5aD19qfU9gjAMrRwzrSlfo0zJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQAAUARxAgAAFEGcAAAARRAnAABAEcQJAABQBHECAAAUQZzwhfD3v/0t/fbrm402WDctVm+SddZqmV132TG33jKqap8FCxbkist+kn379k7n9TqkZfOm2XLTrhnQ/6zMmDGj9oYHFuv3T4xNq9XqL/bPX/78ZNV+T/7x9zn1xGOz+y7bpl3Lpmm1Wv28NnFC7Q0OfKKj+u2QOc9elSl/uKRqrU6dipxyxO75xVUnZPyDQzPtjz/Js3efk6Gn7JvmzRovcoyTDts1t138rbzwq0GZ8+xVeejaU1fkW6CW1avtAWBJzJw5I+3bt89BBx2Sduusk9mzZ+f2W0fnm0d/PRMnTshZ/c/JnDlzMmzo4Bx48CE5+uhvpmWrVvnbs8/kx+cPy5gHfpXfP/l0Gjde9H8Egdp1zsDzsvOXe1Rb27hrt6r/+/Gxv8vjjz2aTTfbIquttnr+8MTYFT0isATatW6e87/bL29NnpHV/ys6Gjesn7OP6507Hvxrbrjvj5k6fXa27NIhP/jWXunz5U2z0+EXZu68D6v2/9bXds7sOR/ksaf/L30aN6yNt0ItKipOHn300YwaNSp//OMf8/rrr2eNNdZI9+7dc+6552brrbeu7fGoRV/usWu+3GPXamt99umbCRNezXUjr81Z/c9J48aN8/z/vZKWLVtWe12HDh1z+KEH5b577s6hhx+xgicHPsv6nTun+7bbf+L2M35wds784YAkyVWX/0ScQKGuOPuQ/P6ZlzN95uz023PLqvU58z5Ml76D8s7M2VVrT/z1pbw+6Z2Mvuhb2X+PLXLbmKertm351WGprKxMkvzlzv4r7g1QhKI+1jVixIhMmDAhp556asaMGZPLL788kydPzvbbb59HH320tsejQC1btUq9eh81dt26dauFyce6b7NtkuSNN15fobMBy0adOkX9pwpYjEP6bJNdtu6c0350+yLbFi6srBYmH/vLuIlJkvZt16y2/nGYsGoq6szJT3/607Rp06ba2t57753OnTvnRz/6UXbfffdamoxSLFy4MAsXLsz06dNzz9135uHfPJSfXH7lp77mscc+CtsuXTdZESMCS+kHp5+Sbx91eBo3aZJttt0+3zuzf7bfcefaHgtYQq3XbJaLzvhqBlzxy7w5ecYSv67HNhslSV54+d/LaTK+iIqKk/8NkyRp1qxZunbtmtdf96/eJKeefEJGXntNkqRBgwa5+NLL861vH/eJ+7/55psZcPYPs9XW3dNnn74rakxgCay++uo57oSTs9POPbJmi5Z59ZXxueryn2S/Pnvm1rt+md337FXbIwJL4PL+B+eliW/nmjufWOLXtGvdPENP2S9/fW5ixjw+bjlOxxdNUXGyODNnzswzzzzzmWdNJk+enClTplRbGz9+/PIcjVpw5g/656hjvpUpkydnzAP35/RTT877s2fntNPPWGTfd955Jwfsu09SWZmbb7nNR0OgMJttvmU22/w/n0vfYaeds89X9s8u22+ZwQPOEifwBbD/Hlukz5e7ZftDf7zEr1lz9Sa596rjU1GRHPGD63yMi2qKj5MTTzwxs2fPztlnn/2p+w0fPjyDBw9eQVNRWzp07JgOHTsmSfbu3SdJcu45/XP4kd9I69atq/abPn16+vbulbfeejNjHnok662/fq3MCyyd5muskV5798kNI6/JnDlz3GEPCta0cYNcetZBGXHb4/n35JlVtwVuUP+jXy+bN2ucD+cvyPtzP6h6zRqrNc6vRpyUdq3XSO/jrsiEN6fVyuyUq+g4GTBgQG655ZZceeWVn3m3rhNOOCEHHnhgtbXx48dn//33X44TUtu6b7Ntfn7Nz/Lqq69Uxcn06dOzz949M3HCq3ngwYez6Wab1fKUwNL4+F9RKyoqankS4NO0XKNZ2rZaPad9fY+c9vU9Ftk+6YmLcv/v/p6DTr82yUdh8sDVJ6fTOi3T57grM+6lt1b0yHwBFBsngwcPznnnnZdhw4blpJNO+sz927Rps9hrVli5Pf7YY6lTp07WW++jMyMfh8mEV1/J/b/+TbbYcsvPOAJQkhnTp+c3D47JppttnkaNGtX2OMCneHvau+n1rcsXWT/j6J7ZZevO2e+kEZk2Y1aS/4TJeu1bpe/xV+XvL76xosflC6LIOBk8eHAGDRqUQYMGpX9/97cmOfH4Y7P66qune/dt02attTJt6tTcc/dduevO2/Pd089I69atM2fOnOy7z975+9+ezUWXXJoF8+fnz0/95ynTrVq1zvobbFCL7wL4b8cec2Tat++QLbbaOi1atsor41/K8Csvy5TJb+eqq0dW7Td1ypT88Q+PJ0leeO6fSZKHf/tgWrVqnZatWmennb9cK/PDqm7eB/PzxF9fWmT9yH23y4KFlVXbGjWsn/uHn5gtNm6f7198d+rVrZNtN+1Utf+U6bPy6htTq77eqmvHrNuuRZJk9aaNUlFRkX57bpEk+etzE/Pav6cvvzdFrSsuToYOHZpBgwblnHPOycCBA2t7HAqx3fY75OYbb8gtN9+UGTNmpFmzZtl0s80z8vqbqh6sOPntt/PXv3z0EKczTj9tkWMcceQ3cs3I61fk2MCn2GSTTXPfPXfkhuuuyexZs7Lmmi2y3Q47Zfi112errbep2u9f/3o+xxx5SLXXnvndk5MkO+785fzy14+s0LmBpdOmxWrp3q1TkuSSMw9cZPvNv3wyxw4cVfX1dw7+co7ct/qDWUdf9K0kybfPvTmj7n9q+Q1LrauoLOgWCZdccknOOOOM7L333osNk+23/+QnCC/Oc889l27duuUvz/4zXTfxjAtYWbw/b0FtjwAsB+13Oa22RwCWoYVzpuWDF2/LuHHjsskS/i5e1JmT+++/P0ny4IMP5sEHH1xke0EdBQAALGNFxcljjz1W2yMAAAC1xFPpAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAiiBOAACAIogTAACgCOIEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAAChCvdoeYHmaN29ekuTll8fX8iTAsjT3wwW1PQKwHCycM622RwCWoYXzZib5z+/kS2KljpPXX389SXLw1/rV8iQAALBqev3117PVVlst0b4VlZWVlct5nlozY8aMjB07Nh06dEjDhg1rexyWo/Hjx2f//ffPfffdl86dO9f2OMAy4u82rHz8vV51zJs3L6+//np69OiRNdZYY4les1KfOVljjTWy33771fYYrECdO3fOJptsUttjAMuYv9uw8vH3etWwpGdMPuaCeAAAoAjiBAAAKII4AQAAiiBOWCm0bt06AwcOTOvWrWt7FGAZ8ncbVj7+XvNpVuq7dQEAAF8czpwAAABFECcAAEARxAkAAFAEcQIAABRBnPCFNmvWrJx22mlp165dGjVqlC222CK33XZbbY8FfA7vvfdezjzzzPTq1SutW7dORUVFBg0aVNtjAZ/Do48+mmOOOSYbb7xxmjZtmnXWWSf77bdf/vrXv9b2aBRGnPCFdsABB+TGG2/MwIED8+tf/zrbbLNNDj300IwePbq2RwNqaNq0abnmmmsyb9687L///rU9DrAMjBgxIhMmTMipp56aMWPG5PLLL8/kyZOz/fbb59FHH63t8SiIWwnzhTVmzJjss88+GT16dA499NCq9V69euW5557La6+9lrp169bihEBNfPyfpYqKikydOrXqmQjOnsAX1+TJk9OmTZtqa7NmzUrnzp3TrVu3PPzww7U0GaVx5oQvrHvvvTfNmjXLgQceWG396KOPzltvvZWnnnqqliYDPo+KiopUVFTU9hjAMvS/YZIkzZo1S9euXfP666/XwkSUSpzwhTVu3Lh06dIl9erVq7a+2WabVW0HAMo0c+bMPPPMM9lkk01qexQKIk74wpo2bVpatGixyPrHa9OmTVvRIwEAS+jEE0/M7Nmzc/bZZ9f2KBSk3mfvAuX6tI9++FgIAJRpwIABueWWW3LllVdm6623ru1xKIgzJ3xhtWzZcrFnR955550kWexZFQCgdg0ePDjnnXdehg0blpNOOqm2x6Ew4oQvrE033TQvvPBC5s+fX239n//8Z5KkW7dutTEWAPAJBg8enEGDBmXQoEHp379/bY9DgcQJX1j9+vXLrFmzcvfdd1dbv/HGG9OuXbtst912tTQZAPC/hg4dmkGDBuWcc87JwIEDa3scCuWaE76wevfunZ49e+b444/Pu+++m86dO+fWW2/Ngw8+mFGjRnnGCXyB/frXv87s2bPz3nvvJUmef/753HXXXUmSPn36pEmTJrU5HrCULrnkkpx77rnZe++9s88+++TJJ5+stn377bevpckojYcw8oU2a9asnH322bnjjjvyzjvvZOONN84Pf/jDHHLIIbU9GvA5dOrUKRMnTlzstldffTWdOnVasQMBn8uuu+6asWPHfuJ2v47yMXECAAAUwTUnAABAEcQJAABQBHECAAAUQZwAAABFECcAAEARxAkAAFAEcQIAABRBnAAAAEUQJwAAQBHECQBLbMKECamoqMgNN9xQtTZo0KBUVFQs9bFGjx6dyy67bNkN9186deqUo4466jP3q6ioyKBBg5b6+B//HC6++OKlH+4zjvnfP1uAVY04AeBz+da3vpU//elPS/265RknAHwx1avtAQBYMebMmZPGjRsv8+O2b98+7du3X+bHBWDV48wJwBfExx+fevbZZ3PAAQdk9dVXT/PmzXPEEUdkypQp1fbt1KlT+vbtm3vuuSdbbrllGjVqlMGDBydJJk2alOOOOy7t27dPgwYNst5662Xw4MGZP39+tWO89dZbOeigg7LaaqulefPmOfjggzNp0qRPnOt/jR49OjvssEOaNWuWZs2aZYsttsjIkSOTJLvuumseeOCBTJw4MRUVFVV/PvbBBx/kvPPOy8Ybb5yGDRumdevWOfrooxd5nx9++GHOPPPMtG3bNk2aNMnOO++cP//5zzX7ASeZMmVKTjjhhHTt2jXNmjVLmzZtsvvuu+eJJ55Y7P4LFy7MsGHD0rFjxzRq1Cjdu3fPI488ssh+L730Ug477LC0adMmDRs2TJcuXfLTn/60xnMCrKycOQH4gunXr18OOuigfOc738lzzz2XAQMG5Pnnn89TTz2V+vXrV+33zDPP5IUXXsg555yT9dZbL02bNs2kSZOy7bbbpk6dOjn33HOzwQYb5E9/+lPOO++8TJgwIddff32Sj86y7Lnnnnnrrbdy/vnnZ6ONNsoDDzyQgw8+eIlmPPfcczN06NAccMAB+d73vpfmzZtn3LhxmThxYpJk+PDhOfbYY/Pyyy/n3nvvrfbahQsXZr/99ssTTzyRM888MzvuuGMmTpyYgQMHZtddd81f/vKXqjNA3/72t3PTTTfljDPOSM+ePTNu3LgccMABee+992r0s33nnXeSJAMHDkzbtm0za9as3Hvvvdl1113zyCOPZNddd622/1VXXZV11103l112WRYuXJgLL7wwvXv3ztixY7PDDjskSZ5//vnsuOOO6dixYy655JK0bds2Dz30UE455ZRMnTo1AwcOrNGsACulSgC+EAYOHFiZpPK73/1utfVbbrmlMknlqFGjqtbWXXfdyrp161a++OKL1fY97rjjKps1a1Y5ceLEausXX3xxZZLK5557rrKysrJyxIgRlUkqf/GLX1Tb79vf/nZlksrrr79+kbk+9sorr1TWrVu38vDDD//U97PPPvtUrrvuuous33rrrZVJKu++++5q608//XRlksrhw4dXVlZWVr7wwguf+vP4xje+8anfv7KysjJJ5cCBAz9x+/z58ys//PDDyj322KOyX79+VeuvvvpqZZLKdu3aVc6ZM6dq/d13361s0aJF5Z577lm1ttdee1W2b9++cubMmdWOfdJJJ1U2atSo8p133ql2zP/+2QKsanysC+AL5vDDD6/29UEHHZR69erld7/7XbX1zTbbLBtttFG1tV/96lfZbbfd0q5du8yfP7/qT+/evZMkY8eOTZL87ne/y2qrrZZ999232usPO+ywz5zvt7/9bRYsWJATTzxxqd/bxzOuscYa+cpXvlJtxi222CJt27bNY489VjVj8sk/j5q6+uqrs9VWW6VRo0apV69e6tevn0ceeSQvvPDCIvsecMABadSoUdXXq622Wr7yla/k8ccfz4IFCzJ37tw88sgj6devX5o0aVLt/fTp0ydz587Nk08+WeNZAVY24gTgC6Zt27bVvq5Xr15atmyZadOmVVtfe+21F3nt22+/nfvvvz/169ev9meTTTZJkkydOjVJMm3atKy11lqf+b0X5+PrQmp6kfzbb7+dGTNmpEGDBovMOWnSpGozLm6mj38eNfGTn/wkxx9/fLbbbrvcfffdefLJJ/P0009n7733zpw5cxbZf3E/j7Zt2+aDDz7IrFmzMm3atMyfPz9XXnnlIu+lT58+Sf7zMwfANScAXziTJk3KOuusU/X1/PnzM23atEV+IV/cReqtWrXKZpttlmHDhi322O3atUuStGzZcrEXli/ugvj/1bp16yTJG2+8kQ4dOnzm/oubsWXLlnnwwQcXu3211VarmvHjmRb386iJUaNGZdddd82IESOqrX/SNSyL+3lMmjQpDRo0SLNmzVK/fv3UrVs3Rx555CeeSVpvvfVqNCvAykicAHzB3HLLLdl6662rvr7jjjsyf/78RS7WXpy+fftmzJgx2WCDDbLmmmt+4n677bZb7rjjjvzyl7+s9tGu0aNHf+b36NWrV+rWrZsRI0ZUXRS+OA0bNlzs2Yi+ffvmtttuy4IFC7Lddtt94us/fr+f9POoiYqKijRs2LDa2j/+8Y/86U9/Wmxo3XPPPbnooouqPtr13nvv5f77788uu+ySunXrpkmTJtltt93y7LPPZrPNNkuDBg1qNBfAqkKcAHzB3HPPPalXr1569uxZdbeuzTffPAcddNBnvnbIkCH57W9/mx133DGnnHJKvvSlL2Xu3LmZMGFCxowZk6uvvjrt27fP17/+9Vx66aX5+te/nmHDhmXDDTfMmDFj8tBDD33m9+jUqVP69++foUOHZs6cOTn00EPTvHnzPP/885k6dWrVLY033XTT3HPPPRkxYkS23nrr1KlTJ927d88hhxySW265JX369Mmpp56abbfdNvXr188bb7yR3/3ud9lvv/3Sr1+/dOnSJUcccUQuu+yy1K9fP3vuuWfGjRuXiy++OKuvvnqNfrZ9+/bN0KFDM3DgwPTo0SMvvvhihgwZkvXWW2+xwVO3bt307Nkzp59+ehYuXJgf//jHeffdd6veY5Jcfvnl2XnnnbPLLrvk+OOPT6dOnfLee+9l/Pjxuf/++/Poo4/WaFaAlZE4AfiCueeeezJo0KCMGDEiFRUV+cpXvpLLLrtsif5Vfu21185f/vKXDB06NBdddFHeeOONrLbaallvvfWy9957V51NadKkSR599NGceuqpOeuss1JRUZFevXrltttuy4477viZ32fIkCHZcMMNc+WVV+bwww9PvXr1suGGG+aUU06p2ufUU0/Nc889l/79+2fmzJmprKxMZWVl6tatm1/+8pe5/PLLc/PNN+f8889PvXr10r59+/To0SObbrpp1TFGjhyZtdZaKzfccEOuuOKKbLHFFrn77rtzyCGH1OAnm5x99tl5//33M3LkyFx44YXp2rVrrr766tx7771VF+L/t5NOOilz587NKaecksmTJ2eTTTbJAw88kJ122qlqn65du+aZZ57J0KFDc84552Ty5MlZY401suGGG1ZddwLARyoqKysra3sIAD7boEGDMnjw4EyZMiWtWrWq7XEAYJlzty4AAKAI4gQAACiCj3UBAABFcOYEAAAogjgBAACKIE4AAIAiiBMAAKAI4gQAACiCOAEAAIogTgAAgCKIEwAAoAjiBAAAKII4AQAAivD/AIOSGhSqyl46AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x960 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Modelo '{nome_estimador}', transformer '{nome_transformer}':\")\n",
    "plot_confusion_matrix(conf_mat=cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda que os estimadores *XGBoost* e *Random Forest* tenham performado muito bem, a performance da Regress√£o Log√≠stica foi incompar√°vel em todas as m√©tricas.\n",
    "\n",
    "Vamos portanto prroseguir com a otimiza√ß√£o desse modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimiza√ß√£o do modelo de **Regress√£o Log√≠stica** com *transformer* ***Word2vec***.\n",
    "\n",
    "Vamos otimizar agora o modelo fitado. Para tal, precisamos alterar seus hiperpar√¢metros e checar se o ajuste √© melhor.\n",
    "\n",
    "Para tal, primeiramente vamos definir quais hiperpar√¢metros vamos testar e com quais valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos par√¢metros de v√°rios estimadores e transformers caso precisemos\n",
    "\n",
    "otimizacoes = dict(\n",
    "    tfidf = dict(\n",
    "        use_idf = [True, False],\n",
    "    ),\n",
    "    word2vec = dict(\n",
    "        vector_size = [10, 50, 100, 200],\n",
    "        vector_combination = [ 'sum', 'mean' ],\n",
    "    ),\n",
    "    doc2vec = dict(\n",
    "        vector_size = [10, 50, 100, 200],\n",
    "    ),\n",
    "    logistic = {\n",
    "        'penalty': ['elasticnet', 'l1', 'l2'],\n",
    "        'fit_intercept': [True, False],\n",
    "        'solver': [ 'lbfgs', 'saga' ],\n",
    "    },\n",
    "    xgboost = {\n",
    "        'criterion': ['friedman_mse', 'mae' ],\n",
    "        'max_features': [ 'log2', 'sqrt' ],\n",
    "        'learning_rate': [ 0.01, 0.05, 0.1, 0.5, 1, ],\n",
    "        'max_depth': [ 3, 4, 5, 10 ],\n",
    "        'n_estimators': [ 5 ,10, 15, 20, 100, 150 ],\n",
    "    },\n",
    "    random_forest = {\n",
    "        'n_estimators': [200, 500],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'max_depth' : [4,5,6,7,8],\n",
    "        'criterion' :['gini', 'entropy']\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora configurar a otimiza√ß√£o:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logistic.word2vec': {'logistic__fit_intercept': [True, False],\n",
      "                       'logistic__penalty': ['elasticnet', 'l1', 'l2'],\n",
      "                       'logistic__solver': ['lbfgs', 'saga'],\n",
      "                       'word2vec__vector_combination': ['sum', 'mean'],\n",
      "                       'word2vec__vector_size': [10, 50, 100, 200]},\n",
      " 'random_forest.word2vec': {'random_forest__criterion': ['gini', 'entropy'],\n",
      "                            'random_forest__max_depth': [4, 5, 6, 7, 8],\n",
      "                            'random_forest__max_features': ['auto',\n",
      "                                                            'sqrt',\n",
      "                                                            'log2'],\n",
      "                            'random_forest__n_estimators': [200, 500],\n",
      "                            'word2vec__vector_combination': ['sum', 'mean'],\n",
      "                            'word2vec__vector_size': [10, 50, 100, 200]},\n",
      " 'xgboost.word2vec': {'word2vec__vector_combination': ['sum', 'mean'],\n",
      "                      'word2vec__vector_size': [10, 50, 100, 200],\n",
      "                      'xgboost__criterion': ['friedman_mse', 'mae'],\n",
      "                      'xgboost__learning_rate': [0.01, 0.05, 0.1, 0.5, 1],\n",
      "                      'xgboost__max_depth': [3, 4, 5, 10],\n",
      "                      'xgboost__max_features': ['log2', 'sqrt'],\n",
      "                      'xgboost__n_estimators': [5, 10, 15, 20, 100, 150]}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# para cada nome de modelo a ser otimizado, haver√° um dicion√°rio com a configura√ß√£o da otimiza√ß√£o\n",
    "\n",
    "nomes_modelos = [ 'logistic.word2vec', 'random_forest.word2vec', 'xgboost.word2vec']\n",
    "\n",
    "params = {}\n",
    "\n",
    "for nome in nomes_modelos:\n",
    "    params[nome] = {}\n",
    "    for nome_pipe in nome.split('.'):\n",
    "        for nome_param, valores_param in otimizacoes.get(nome_pipe, {}).items():\n",
    "            params[nome][f'{nome_pipe}__{nome_param}'] = valores_param\n",
    "    \n",
    "    if not params[nome]:\n",
    "        _ = params.pop(nome, None)\n",
    "\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, vamos executar a otimiza√ß√£o.\n",
    "\n",
    "Utilizaremos uma fun√ß√£o de perda [***log loss***](https://en.wikipedia.org/wiki/Loss_functions_for_classification#Logistic_loss). \n",
    "\n",
    "A acur√°cia (ou nenhuma outra fun√ß√£o que use como par√¢metro de entrada as predi√ß√µes em si) n√£o √© recomendada como uma fun√ß√£o de perda pois √© uma [fun√ß√£o de compara√ß√£o impr√≥pria (*Improper scoring rule*)](https://en.wikipedia.org/wiki/Scoring_rule); logo, n√£o √© adequada para comparar predi√ß√µes probabil√≠sticas.\n",
    "\n",
    "Exemplos de fun√ß√µes de compara√ß√£o de predi√ß√µes probabil√≠sticas s√£o a pr√≥pria *log loss*, a [*Brier loss*](https://en.wikipedia.org/wiki/Brier_score), a [*Square loss*](https://en.wikipedia.org/wiki/Loss_functions_for_classification#Square_loss), entre outras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando busca...\n",
      "Procurando hiperpar√¢metros √≥timos para o modelo 'logistic' com transformer 'word2vec'... \n",
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 96 is smaller than n_iter=150. Running 96 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "144 fits failed out of a total of 288.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.76701267 -0.56945814 -0.68891017 -0.79647055 -0.58940833 -0.58997632\n",
      " -0.72407629 -0.80011059 -0.74581994 -0.45545524 -0.52831478 -0.65801373\n",
      " -0.73446171 -0.75815901 -0.78081888 -0.78758846 -0.76818417 -0.58505772\n",
      " -0.67556406 -0.74003459 -0.73448554 -0.75821345 -0.78079825 -0.78809647\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.84079771 -0.62987467 -0.74959468 -0.85819492 -0.7682071  -0.75473572\n",
      " -0.9456618  -1.05650262 -0.8281102  -0.52505776 -0.59577468 -0.72298514\n",
      " -0.9218115  -0.99214081 -1.02150125 -1.03773229 -0.84162889 -0.64504356\n",
      " -0.73649016 -0.80319915 -0.92187658 -0.99218268 -1.02139891 -1.0377124 ]\n",
      "  warnings.warn(\n",
      "E:\\programacao\\python\\Anaconda3\\envs\\sentiment_analysis_twitter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... OK. (Dura√ß√£o da busca: 0:00:23.235845)\n",
      "\n",
      "Procurando hiperpar√¢metros √≥timos para o modelo 'random_forest' com transformer 'word2vec'... \n",
      "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n",
      "... OK. (Dura√ß√£o da busca: 0:04:12.209363)\n",
      "\n",
      "Procurando hiperpar√¢metros √≥timos para o modelo 'xgboost' com transformer 'word2vec'... \n",
      "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n",
      "[17:14:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"criterion\", \"max_features\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "... OK. (Dura√ß√£o da busca: 0:06:31.588536)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from datetime import datetime as dt\n",
    "\n",
    "nome_score = 'neg_log_loss' # por que negativada? fun√ß√µes de perda tem seu √≥timo no ponto de m√≠nimo.\n",
    "                            # a negativa√ß√£o transforma o ponto √≥timo no ponto de m√°ximo,\n",
    "                            # o que √© consistente com as outras m√©tricas de desempenho\n",
    "                            # dispon√≠veis no scikit-learn\n",
    "searchers = {}\n",
    "\n",
    "cv = StratifiedKFold(\n",
    "    n_splits = 3,\n",
    ")\n",
    "\n",
    "# deletar a vari√°vel t0 caso exista, para que a l√≥gica de timing dos testes n√£o se confunda\n",
    "try:\n",
    "    del t0\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "print('Iniciando busca...')\n",
    "for nome_pipeline, hiperparams_otim in params.items():\n",
    "\n",
    "    nome_estimador, nome_transformer = nome_pipeline.split('.')\n",
    "    modelo = pipelines[nome_pipeline]\n",
    "    \n",
    "    try:\n",
    "        tfim = dt.now()\n",
    "        delta = tfim - t0\n",
    "        print(f\"... OK. (Dura√ß√£o da busca: {delta})\\n\")\n",
    "    except NameError:   # variavel t0 n√£o existe: primeira itera√ß√£o do loop\n",
    "        pass\n",
    "\n",
    "    print(f\"Procurando hiperpar√¢metros √≥timos para o modelo '{nome_estimador}' com transformer '{nome_transformer}'... \")\n",
    "    t0 = dt.now()\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator = modelo, \n",
    "        param_distributions = hiperparams_otim, \n",
    "        scoring = nome_score,\n",
    "        n_iter = 150,\n",
    "        cv = cv, \n",
    "        verbose = 2,\n",
    "        n_jobs = -1,\n",
    "    )\n",
    "    \n",
    "    searchers[nome_pipeline] = random_search.fit(X_train, y_train)\n",
    "\n",
    "tfim = dt.now()\n",
    "delta = tfim - t0\n",
    "print(f\"... OK. (Dura√ß√£o da busca: {delta})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores par√¢metros para o modelo 'logistic' com transformer 'word2vec':\n",
      "{'logistic__fit_intercept': True,\n",
      " 'logistic__penalty': 'l2',\n",
      " 'logistic__solver': 'lbfgs',\n",
      " 'word2vec__vector_combination': 'sum',\n",
      " 'word2vec__vector_size': 50}\n",
      "\n",
      "Melhores par√¢metros para o modelo 'random_forest' com transformer 'word2vec':\n",
      "{'random_forest__criterion': 'entropy',\n",
      " 'random_forest__max_depth': 8,\n",
      " 'random_forest__max_features': 'auto',\n",
      " 'random_forest__n_estimators': 200,\n",
      " 'word2vec__vector_combination': 'mean',\n",
      " 'word2vec__vector_size': 200}\n",
      "\n",
      "Melhores par√¢metros para o modelo 'xgboost' com transformer 'word2vec':\n",
      "{'word2vec__vector_combination': 'sum',\n",
      " 'word2vec__vector_size': 200,\n",
      " 'xgboost__criterion': 'friedman_mse',\n",
      " 'xgboost__learning_rate': 0.5,\n",
      " 'xgboost__max_depth': 4,\n",
      " 'xgboost__max_features': 'sqrt',\n",
      " 'xgboost__n_estimators': 150}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for nome_pipeline, searcher in searchers.items():\n",
    "    nome_estimador, nome_transformer = nome_pipeline.split('.')\n",
    "    print(f\"Melhores par√¢metros para o modelo '{nome_estimador}' com transformer '{nome_transformer}':\")\n",
    "    pprint(searcher.best_params_)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A melhora no desempenho de cada um dos modelos √©:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvresults = {}\n",
    "\n",
    "for nome_modelo, searcher in searchers.items():\n",
    "    rsdf = pd.DataFrame(searcher.cv_results_)\n",
    "    rsdf = rsdf.set_index([ col for col in rsdf.columns if col.startswith('param_') ])\n",
    "    cvresults[nome_modelo] = rsdf.sort_values(by = 'rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_xgboost__n_estimators</th>\n",
       "      <th>param_xgboost__max_features</th>\n",
       "      <th>param_xgboost__max_depth</th>\n",
       "      <th>param_xgboost__learning_rate</th>\n",
       "      <th>param_xgboost__criterion</th>\n",
       "      <th>param_word2vec__vector_size</th>\n",
       "      <th>param_word2vec__vector_combination</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <th>sqrt</th>\n",
       "      <th>4</th>\n",
       "      <th>0.50</th>\n",
       "      <th>friedman_mse</th>\n",
       "      <th>200</th>\n",
       "      <th>sum</th>\n",
       "      <td>18.551377</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.057845</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>{'xgboost__n_estimators': 150, 'xgboost__max_f...</td>\n",
       "      <td>-0.164951</td>\n",
       "      <td>-0.238302</td>\n",
       "      <td>-0.207046</td>\n",
       "      <td>-0.203433</td>\n",
       "      <td>0.030054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <th>log2</th>\n",
       "      <th>4</th>\n",
       "      <th>0.50</th>\n",
       "      <th>friedman_mse</th>\n",
       "      <th>200</th>\n",
       "      <th>sum</th>\n",
       "      <td>19.734877</td>\n",
       "      <td>0.053083</td>\n",
       "      <td>0.057181</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>{'xgboost__n_estimators': 100, 'xgboost__max_f...</td>\n",
       "      <td>-0.180368</td>\n",
       "      <td>-0.222716</td>\n",
       "      <td>-0.215291</td>\n",
       "      <td>-0.206125</td>\n",
       "      <td>0.018464</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">150</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">log2</th>\n",
       "      <th>5</th>\n",
       "      <th>0.50</th>\n",
       "      <th>friedman_mse</th>\n",
       "      <th>200</th>\n",
       "      <th>sum</th>\n",
       "      <td>24.185971</td>\n",
       "      <td>0.264553</td>\n",
       "      <td>0.059508</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>{'xgboost__n_estimators': 150, 'xgboost__max_f...</td>\n",
       "      <td>-0.191525</td>\n",
       "      <td>-0.220275</td>\n",
       "      <td>-0.209139</td>\n",
       "      <td>-0.206979</td>\n",
       "      <td>0.011836</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>1.00</th>\n",
       "      <th>friedman_mse</th>\n",
       "      <th>200</th>\n",
       "      <th>sum</th>\n",
       "      <td>17.210962</td>\n",
       "      <td>0.156897</td>\n",
       "      <td>0.058842</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>{'xgboost__n_estimators': 150, 'xgboost__max_f...</td>\n",
       "      <td>-0.196606</td>\n",
       "      <td>-0.236192</td>\n",
       "      <td>-0.224281</td>\n",
       "      <td>-0.219027</td>\n",
       "      <td>0.016582</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sqrt</th>\n",
       "      <th>4</th>\n",
       "      <th>0.10</th>\n",
       "      <th>mae</th>\n",
       "      <th>200</th>\n",
       "      <th>mean</th>\n",
       "      <td>23.114171</td>\n",
       "      <td>0.445356</td>\n",
       "      <td>0.064827</td>\n",
       "      <td>0.004886</td>\n",
       "      <td>{'xgboost__n_estimators': 150, 'xgboost__max_f...</td>\n",
       "      <td>-0.194397</td>\n",
       "      <td>-0.207562</td>\n",
       "      <td>-0.265863</td>\n",
       "      <td>-0.222608</td>\n",
       "      <td>0.031055</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">sqrt</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.01</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">mae</th>\n",
       "      <th>200</th>\n",
       "      <th>mean</th>\n",
       "      <td>2.331430</td>\n",
       "      <td>0.821182</td>\n",
       "      <td>0.062832</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>{'xgboost__n_estimators': 5, 'xgboost__max_fea...</td>\n",
       "      <td>-1.053916</td>\n",
       "      <td>-1.052487</td>\n",
       "      <td>-1.055161</td>\n",
       "      <td>-1.053855</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <th>sum</th>\n",
       "      <td>3.425836</td>\n",
       "      <td>0.100201</td>\n",
       "      <td>0.052526</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>{'xgboost__n_estimators': 5, 'xgboost__max_fea...</td>\n",
       "      <td>-1.056761</td>\n",
       "      <td>-1.064837</td>\n",
       "      <td>-1.058407</td>\n",
       "      <td>-1.060001</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>log2</th>\n",
       "      <th>3</th>\n",
       "      <th>0.01</th>\n",
       "      <th>mae</th>\n",
       "      <th>10</th>\n",
       "      <th>sum</th>\n",
       "      <td>0.985696</td>\n",
       "      <td>0.069658</td>\n",
       "      <td>0.045878</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>{'xgboost__n_estimators': 15, 'xgboost__max_fe...</td>\n",
       "      <td>-1.071622</td>\n",
       "      <td>-1.062772</td>\n",
       "      <td>-1.065590</td>\n",
       "      <td>-1.066661</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">sqrt</th>\n",
       "      <th>5</th>\n",
       "      <th>0.01</th>\n",
       "      <th>friedman_mse</th>\n",
       "      <th>50</th>\n",
       "      <th>sum</th>\n",
       "      <td>1.450453</td>\n",
       "      <td>0.048047</td>\n",
       "      <td>0.055186</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>{'xgboost__n_estimators': 5, 'xgboost__max_fea...</td>\n",
       "      <td>-1.067377</td>\n",
       "      <td>-1.069014</td>\n",
       "      <td>-1.075904</td>\n",
       "      <td>-1.070765</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0.01</th>\n",
       "      <th>friedman_mse</th>\n",
       "      <th>200</th>\n",
       "      <th>sum</th>\n",
       "      <td>1.158235</td>\n",
       "      <td>0.101625</td>\n",
       "      <td>0.053856</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>{'xgboost__n_estimators': 5, 'xgboost__max_fea...</td>\n",
       "      <td>-1.072881</td>\n",
       "      <td>-1.068899</td>\n",
       "      <td>-1.072251</td>\n",
       "      <td>-1.071344</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                       mean_fit_time  \\\n",
       "param_xgboost__n_estimators param_xgboost__max_features param_xgboost__max_depth param_xgboost__learning_rate param_xgboost__criterion param_word2vec__vector_size param_word2vec__vector_combination                  \n",
       "150                         sqrt                        4                        0.50                         friedman_mse             200                         sum                                     18.551377   \n",
       "100                         log2                        4                        0.50                         friedman_mse             200                         sum                                     19.734877   \n",
       "150                         log2                        5                        0.50                         friedman_mse             200                         sum                                     24.185971   \n",
       "                                                        4                        1.00                         friedman_mse             200                         sum                                     17.210962   \n",
       "                            sqrt                        4                        0.10                         mae                      200                         mean                                    23.114171   \n",
       "...                                                                                                                                                                                                              ...   \n",
       "5                           sqrt                        10                       0.01                         mae                      200                         mean                                     2.331430   \n",
       "                                                                                                                                       100                         sum                                      3.425836   \n",
       "15                          log2                        3                        0.01                         mae                      10                          sum                                      0.985696   \n",
       "5                           sqrt                        5                        0.01                         friedman_mse             50                          sum                                      1.450453   \n",
       "                                                        4                        0.01                         friedman_mse             200                         sum                                      1.158235   \n",
       "\n",
       "                                                                                                                                                                                                       std_fit_time  \\\n",
       "param_xgboost__n_estimators param_xgboost__max_features param_xgboost__max_depth param_xgboost__learning_rate param_xgboost__criterion param_word2vec__vector_size param_word2vec__vector_combination                 \n",
       "150                         sqrt                        4                        0.50                         friedman_mse             200                         sum                                     0.314286   \n",
       "100                         log2                        4                        0.50                         friedman_mse             200                         sum                                     0.053083   \n",
       "150                         log2                        5                        0.50                         friedman_mse             200                         sum                                     0.264553   \n",
       "                                                        4                        1.00                         friedman_mse             200                         sum                                     0.156897   \n",
       "                            sqrt                        4                        0.10                         mae                      200                         mean                                    0.445356   \n",
       "...                                                                                                                                                                                                             ...   \n",
       "5                           sqrt                        10                       0.01                         mae                      200                         mean                                    0.821182   \n",
       "                                                                                                                                       100                         sum                                     0.100201   \n",
       "15                          log2                        3                        0.01                         mae                      10                          sum                                     0.069658   \n",
       "5                           sqrt                        5                        0.01                         friedman_mse             50                          sum                                     0.048047   \n",
       "                                                        4                        0.01                         friedman_mse             200                         sum                                     0.101625   \n",
       "\n",
       "                                                                                                                                                                                                       mean_score_time  \\\n",
       "param_xgboost__n_estimators param_xgboost__max_features param_xgboost__max_depth param_xgboost__learning_rate param_xgboost__criterion param_word2vec__vector_size param_word2vec__vector_combination                    \n",
       "150                         sqrt                        4                        0.50                         friedman_mse             200                         sum                                        0.057845   \n",
       "100                         log2                        4                        0.50                         friedman_mse             200                         sum                                        0.057181   \n",
       "150                         log2                        5                        0.50                         friedman_mse             200                         sum                                        0.059508   \n",
       "                                                        4                        1.00                         friedman_mse             200                         sum                                        0.058842   \n",
       "                            sqrt                        4                        0.10                         mae                      200                         mean                                       0.064827   \n",
       "...                                                                                                                                                                                                                ...   \n",
       "5                           sqrt                        10                       0.01                         mae                      200                         mean                                       0.062832   \n",
       "                                                                                                                                       100                         sum                                        0.052526   \n",
       "15                          log2                        3                        0.01                         mae                      10                          sum                                        0.045878   \n",
       "5                           sqrt                        5                        0.01                         friedman_mse             50                          sum                                        0.055186   \n",
       "                                                        4                        0.01                         friedman_mse             200                         sum                                        0.053856   \n",
       "\n",
       "                                                                                                                                                                                                       std_score_time  \\\n",
       "param_xgboost__n_estimators param_xgboost__max_features param_xgboost__max_depth param_xgboost__learning_rate param_xgboost__criterion param_word2vec__vector_size param_word2vec__vector_combination                   \n",
       "150                         sqrt                        4                        0.50                         friedman_mse             200                         sum                                       0.001411   \n",
       "100                         log2                        4                        0.50                         friedman_mse             200                         sum                                       0.002050   \n",
       "150                         log2                        5                        0.50                         friedman_mse             200                         sum                                       0.002049   \n",
       "                                                        4                        1.00                         friedman_mse             200                         sum                                       0.002154   \n",
       "                            sqrt                        4                        0.10                         mae                      200                         mean                                      0.004886   \n",
       "...                                                                                                                                                                                                               ...   \n",
       "5                           sqrt                        10                       0.01                         mae                      200                         mean                                      0.002155   \n",
       "                                                                                                                                       100                         sum                                       0.002860   \n",
       "15                          log2                        3                        0.01                         mae                      10                          sum                                       0.002821   \n",
       "5                           sqrt                        5                        0.01                         friedman_mse             50                          sum                                       0.005298   \n",
       "                                                        4                        0.01                         friedman_mse             200                         sum                                       0.001629   \n",
       "\n",
       "                                                                                                                                                                                                                                                  params  \\\n",
       "param_xgboost__n_estimators param_xgboost__max_features param_xgboost__max_depth param_xgboost__learning_rate param_xgboost__criterion param_word2vec__vector_size param_word2vec__vector_combination                                                      \n",
       "150                         sqrt                        4                        0.50                         friedman_mse             200                         sum                                 {'xgboost__n_estimators': 150, 'xgboost__max_f...   \n",
       "100                         log2                        4                        0.50                         friedman_mse             200                         sum                                 {'xgboost__n_estimators': 100, 'xgboost__max_f...   \n",
       "150                         log2                        5                        0.50                         friedman_mse             200                         sum                                 {'xgboost__n_estimators': 150, 'xgboost__max_f...   \n",
       "                                                        4                        1.00                         friedman_mse             200                         sum                                 {'xgboost__n_estimators': 150, 'xgboost__max_f...   \n",
       "                            sqrt                        4                        0.10                         mae                      200                         mean                                {'xgboost__n_estimators': 150, 'xgboost__max_f...   \n",
       "...                                                                                                                                                                                                                                                  ...   \n",
       "5                           sqrt                        10                       0.01                         mae                      200                         mean                                {'xgboost__n_estimators': 5, 'xgboost__max_fea...   \n",
       "                                                                                                                                       100                         sum                                 {'xgboost__n_estimators': 5, 'xgboost__max_fea...   \n",
       "15                          log2                        3                        0.01                         mae                      10                          sum                                 {'xgboost__n_estimators': 15, 'xgboost__max_fe...   \n",
       "5                           sqrt                        5                        0.01                         friedman_mse             50                          sum                                 {'xgboost__n_estimators': 5, 'xgboost__max_fea...   \n",
       "                                                        4                        0.01                         friedman_mse             200                         sum                                 {'xgboost__n_estimators': 5, 'xgboost__max_fea...   \n",
       "\n",
       "                                                                                                                                                                                                       split0_test_score  \\\n",
       "param_xgboost__n_estimators param_xgboost__max_features param_xgboost__max_depth param_xgboost__learning_rate param_xgboost__criterion param_word2vec__vector_size param_word2vec__vector_combination                      \n",
       "150                         sqrt                        4                        0.50                         friedman_mse             200                         sum                                         -0.164951   \n",
       "100                         log2                        4                        0.50                         friedman_mse             200                         sum                                         -0.180368   \n",
       "150                         log2                        5                        0.50                         friedman_mse             200                         sum                                         -0.191525   \n",
       "                                                        4                        1.00                         friedman_mse             200                         sum                                         -0.196606   \n",
       "                            sqrt                        4                        0.10                         mae                      200                         mean                                        -0.194397   \n",
       "...                                                                                                                                                                                                                  ...   \n",
       "5                           sqrt                        10                       0.01                         mae                      200                         mean                                        -1.053916   \n",
       "                                                                                                                                       100                         sum                                         -1.056761   \n",
       "15                          log2                        3                        0.01                         mae                      10                          sum                                         -1.071622   \n",
       "5                           sqrt                        5                        0.01                         friedman_mse             50                          sum                                         -1.067377   \n",
       "                                                        4                        0.01                         friedman_mse             200                         sum                                         -1.072881   \n",
       "\n",
       "                                                                                                                                                                                                       split1_test_score  \\\n",
       "param_xgboost__n_estimators param_xgboost__max_features param_xgboost__max_depth param_xgboost__learning_rate param_xgboost__criterion param_word2vec__vector_size param_word2vec__vector_combination                      \n",
       "150                         sqrt                        4                        0.50                         friedman_mse             200                         sum                                         -0.238302   \n",
       "100                         log2                        4                        0.50                         friedman_mse             200                         sum                                         -0.222716   \n",
       "150                         log2                        5                        0.50                         friedman_mse             200                         sum                                         -0.220275   \n",
       "                                                        4                        1.00                         friedman_mse             200                         sum                                         -0.236192   \n",
       "                            sqrt                        4                        0.10                         mae                      200                         mean                                        -0.207562   \n",
       "...                                                                                                                                                                                                                  ...   \n",
       "5                           sqrt                        10                       0.01                         mae                      200                         mean                                        -1.052487   \n",
       "                                                                                                                                       100                         sum                                         -1.064837   \n",
       "15                          log2                        3                        0.01                         mae                      10                          sum                                         -1.062772   \n",
       "5                           sqrt                        5                        0.01                         friedman_mse             50                          sum                                         -1.069014   \n",
       "                                                        4                        0.01                         friedman_mse             200                         sum                                         -1.068899   \n",
       "\n",
       "                                                                                                                                                                                                       split2_test_score  \\\n",
       "param_xgboost__n_estimators param_xgboost__max_features param_xgboost__max_depth param_xgboost__learning_rate param_xgboost__criterion param_word2vec__vector_size param_word2vec__vector_combination                      \n",
       "150                         sqrt                        4                        0.50                         friedman_mse             200                         sum                                         -0.207046   \n",
       "100                         log2                        4                        0.50                         friedman_mse             200                         sum                                         -0.215291   \n",
       "150                         log2                        5                        0.50                         friedman_mse             200                         sum                                         -0.209139   \n",
       "                                                        4                        1.00                         friedman_mse             200                         sum                                         -0.224281   \n",
       "                            sqrt                        4                        0.10                         mae                      200                         mean                                        -0.265863   \n",
       "...                                                                                                                                                                                                                  ...   \n",
       "5                           sqrt                        10                       0.01                         mae                      200                         mean                                        -1.055161   \n",
       "                                                                                                                                       100                         sum                                         -1.058407   \n",
       "15                          log2                        3                        0.01                         mae                      10                          sum                                         -1.065590   \n",
       "5                           sqrt                        5                        0.01                         friedman_mse             50                          sum                                         -1.075904   \n",
       "                                                        4                        0.01                         friedman_mse             200                         sum                                         -1.072251   \n",
       "\n",
       "                                                                                                                                                                                                       mean_test_score  \\\n",
       "param_xgboost__n_estimators param_xgboost__max_features param_xgboost__max_depth param_xgboost__learning_rate param_xgboost__criterion param_word2vec__vector_size param_word2vec__vector_combination                    \n",
       "150                         sqrt                        4                        0.50                         friedman_mse             200                         sum                                       -0.203433   \n",
       "100                         log2                        4                        0.50                         friedman_mse             200                         sum                                       -0.206125   \n",
       "150                         log2                        5                        0.50                         friedman_mse             200                         sum                                       -0.206979   \n",
       "                                                        4                        1.00                         friedman_mse             200                         sum                                       -0.219027   \n",
       "                            sqrt                        4                        0.10                         mae                      200                         mean                                      -0.222608   \n",
       "...                                                                                                                                                                                                                ...   \n",
       "5                           sqrt                        10                       0.01                         mae                      200                         mean                                      -1.053855   \n",
       "                                                                                                                                       100                         sum                                       -1.060001   \n",
       "15                          log2                        3                        0.01                         mae                      10                          sum                                       -1.066661   \n",
       "5                           sqrt                        5                        0.01                         friedman_mse             50                          sum                                       -1.070765   \n",
       "                                                        4                        0.01                         friedman_mse             200                         sum                                       -1.071344   \n",
       "\n",
       "                                                                                                                                                                                                       std_test_score  \\\n",
       "param_xgboost__n_estimators param_xgboost__max_features param_xgboost__max_depth param_xgboost__learning_rate param_xgboost__criterion param_word2vec__vector_size param_word2vec__vector_combination                   \n",
       "150                         sqrt                        4                        0.50                         friedman_mse             200                         sum                                       0.030054   \n",
       "100                         log2                        4                        0.50                         friedman_mse             200                         sum                                       0.018464   \n",
       "150                         log2                        5                        0.50                         friedman_mse             200                         sum                                       0.011836   \n",
       "                                                        4                        1.00                         friedman_mse             200                         sum                                       0.016582   \n",
       "                            sqrt                        4                        0.10                         mae                      200                         mean                                      0.031055   \n",
       "...                                                                                                                                                                                                               ...   \n",
       "5                           sqrt                        10                       0.01                         mae                      200                         mean                                      0.001093   \n",
       "                                                                                                                                       100                         sum                                       0.003484   \n",
       "15                          log2                        3                        0.01                         mae                      10                          sum                                       0.003692   \n",
       "5                           sqrt                        5                        0.01                         friedman_mse             50                          sum                                       0.003695   \n",
       "                                                        4                        0.01                         friedman_mse             200                         sum                                       0.001748   \n",
       "\n",
       "                                                                                                                                                                                                       rank_test_score  \n",
       "param_xgboost__n_estimators param_xgboost__max_features param_xgboost__max_depth param_xgboost__learning_rate param_xgboost__criterion param_word2vec__vector_size param_word2vec__vector_combination                   \n",
       "150                         sqrt                        4                        0.50                         friedman_mse             200                         sum                                               1  \n",
       "100                         log2                        4                        0.50                         friedman_mse             200                         sum                                               2  \n",
       "150                         log2                        5                        0.50                         friedman_mse             200                         sum                                               3  \n",
       "                                                        4                        1.00                         friedman_mse             200                         sum                                               4  \n",
       "                            sqrt                        4                        0.10                         mae                      200                         mean                                              5  \n",
       "...                                                                                                                                                                                                                ...  \n",
       "5                           sqrt                        10                       0.01                         mae                      200                         mean                                            146  \n",
       "                                                                                                                                       100                         sum                                             147  \n",
       "15                          log2                        3                        0.01                         mae                      10                          sum                                             148  \n",
       "5                           sqrt                        5                        0.01                         friedman_mse             50                          sum                                             149  \n",
       "                                                        4                        0.01                         friedman_mse             200                         sum                                             150  \n",
       "\n",
       "[150 rows x 11 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvresults['xgboost.word2vec'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando score = 'neg_log_loss'\n",
      "\n",
      "Resultados para modelo 'logistic' com transformer 'word2vec':\n",
      "     Score 'neg_log_loss' original: -0.37710553682403164\n",
      "    Score 'neg_log_loss' otimizado: -0.45545523997773146\n",
      "                          Melhoria: -17.203%\n",
      "\n",
      "Resultados para modelo 'random_forest' com transformer 'word2vec':\n",
      "     Score 'neg_log_loss' original: -0.5801350818124781\n",
      "    Score 'neg_log_loss' otimizado: -0.44714173887737935\n",
      "                          Melhoria: 29.743%\n",
      "\n",
      "Resultados para modelo 'xgboost' com transformer 'word2vec':\n",
      "     Score 'neg_log_loss' original: -0.4200579808129405\n",
      "    Score 'neg_log_loss' otimizado: -0.20343321787893776\n",
      "                          Melhoria: 106.484%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import SCORERS\n",
    "\n",
    "fscore = SCORERS[nome_score]\n",
    "\n",
    "print(f\"Usando score = '{nome_score}'\\n\")\n",
    "\n",
    "best_scores = { nome_modelo: searcher.best_score_ for nome_modelo, seacher in searchers.items() }\n",
    "\n",
    "for nome_modelo in nomes_modelos:\n",
    "    nome_estimador, nome_transformer = nome_modelo.split('.')\n",
    "    modelo = pipelines[nome_pipeline]\n",
    "\n",
    "    print(f\"Resultados para modelo '{nome_estimador}' com transformer '{nome_transformer}':\")\n",
    "    score_original = fscore(\n",
    "        estimator = pipelines[nome_modelo],\n",
    "        X = X_test,\n",
    "        y_true = y_test,\n",
    "    )\n",
    "    score_otimizado = cvresults[nome_modelo].iloc[0]['mean_test_score']\n",
    "\n",
    "    if nome_score.startswith('neg'):\n",
    "        melhoria = score_original / score_otimizado - 1\n",
    "    else:\n",
    "        melhoria = score_otimizado / score_original - 1\n",
    "\n",
    "    frase_score_orig = f\"Score '{nome_score}' original\"\n",
    "    frase_score_opt = f\"Score '{nome_score}' otimizado\"\n",
    "    frase_melhoria = 'Melhoria'\n",
    "\n",
    "    ncaract = len(frase_score_opt) + 4\n",
    "\n",
    "    print(f\"{frase_score_orig:>{ncaract}s}: {score_original:}\")\n",
    "    print(f\"{frase_score_opt:>{ncaract}s}: {score_otimizado:}\")\n",
    "    print(f\"{frase_melhoria:>{ncaract}s}: {melhoria:.3%}\")\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surpreendentemente, **o modelo *XGBoost* com o *transformer* *Word2Vec* teve uma melhora significativa na *performance*, ultrapassando o modelo de regress√£o log√≠stica**. Vamos ent√£o utiliz√°-lo, com os par√¢metros otimizados, para predizer o sentimento de novos *tweets*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Par√¢metros otimizados do modelo 'xgboost' com transformer 'word2vec':\n",
      "\n",
      "{'word2vec__vector_combination': 'sum',\n",
      " 'word2vec__vector_size': 200,\n",
      " 'xgboost__criterion': 'friedman_mse',\n",
      " 'xgboost__learning_rate': 0.5,\n",
      " 'xgboost__max_depth': 4,\n",
      " 'xgboost__max_features': 'sqrt',\n",
      " 'xgboost__n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "modelo_final = 'xgboost.word2vec'\n",
    "nome_estimador, nome_transformer = modelo_final.split('.')\n",
    "\n",
    "print(f\"Par√¢metros otimizados do modelo '{nome_estimador}' com transformer '{nome_transformer}':\\n\")\n",
    "\n",
    "params_finais = cvresults[modelo_final].iloc[0]['params']\n",
    "\n",
    "pprint(params_finais)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "042e8b181f7a654ab04b43e4c16105a209d78a4c994215d11e51fd97fdddcfc1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('sentiment_analysis_twitter': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
